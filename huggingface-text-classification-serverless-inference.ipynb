{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Serverless Inference\n",
    "## HuggingFace Text Classification example\n",
    "\n",
    "Amazon SageMaker Serverless Inference is a purpose-built inference option that makes it easy for you to deploy and scale ML models. Serverless Inference is ideal for workloads which have idle periods between traffic spurts and can tolerate cold starts. Serverless endpoints automatically launch compute resources and scale them in and out depending on traffic, eliminating the need to choose instance types or manage scaling policies. This takes away the undifferentiated heavy lifting of selecting and managing servers. Serverless Inference integrates with AWS Lambda to offer you high availability, built-in fault tolerance and automatic scaling.\n",
    "\n",
    "Serverless Inference is a great choice for customers that have intermittent or unpredictable prediction traffic. For example, a document processing service used to extract and analyze data on a periodic basis. Customers that choose Serverless Inference should make sure that their workloads can tolerate cold starts. A cold start can occur when your endpoint doesn’t receive traffic for a period of time. It can also occur when your concurrent requests exceed the current request usage. The cold start time will depend on your model size, how long it takes to download, and your container startup time.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Text Classification can be used to solve various use-cases like sentiment analysis, spam detection, hashtag prediction etc. \n",
    "\n",
    "\n",
    "This notebook demonstrates the use of the [HuggingFace `transformers` library](https://huggingface.co/transformers/) together with a custom Amazon sagemaker-sdk extension to fine-tune a pre-trained transformer on multi class text classification. In particular, the pre-trained model will be fine-tuned using the [`20 newsgroups dataset`](http://qwone.com/~jason/20Newsgroups/). To get started, we need to set up the environment with a few prerequisite steps, for permissions, configurations, and so on.\n",
    "\n",
    "<b>Notebook Setting</b>\n",
    "- <b>SageMaker Classic Notebook Instance</b>: `ml.m5.xlarge` Notebook Instance & `conda_pytorch_p36 Kernel`\n",
    "- <b>SageMaker Studio</b>: `Python 3 (PyTorch 1.6 Python 3.6 CPU Optimized)`\n",
    "- <b>Regions Available</b>: SageMaker Serverless Inference is currently available in the following regions: US East (Northern Virginia), US East (Ohio), US West (Oregon), EU (Ireland), Asia Pacific (Tokyo) and Asia Pacific (Sydney)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- Setup\n",
    "- Data Preprocessing\n",
    "- Model Training\n",
    "- Deployment\n",
    "    - Endpoint Configuration (Adjust for Serverless)\n",
    "    - Serverless Endpoint Creation\n",
    "    - Endpoint Invocation\n",
    "- Cleanup\n",
    "- Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development Environment and Permissions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "If you run this notebook in SageMaker Studio, you need to make sure `ipywidgets` is installed and restart the kernel, so please uncomment the code in the next cell, and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# import IPython\n",
    "# import sys\n",
    "\n",
    "# !{sys.executable} -m pip install ipywidgets\n",
    "# IPython.Application.instance().kernel.do_shutdown(True)  # has to restart kernel so changes are used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's install the required packages from HuggingFace and SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting scikit_learn>=1.1.2\n",
      "  Downloading scikit_learn-1.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m132.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sagemaker>=2.110.1 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (2.111.0)\n",
      "Requirement already satisfied: transformers>=4.21.1 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (4.22.2)\n",
      "Requirement already satisfied: datasets>=2.2.0 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: nltk>=3.4.4 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (3.7)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from scikit_learn>=1.1.2) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from scikit_learn>=1.1.2) (1.20.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from scikit_learn>=1.1.2) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from scikit_learn>=1.1.2) (2.2.0)\n",
      "Requirement already satisfied: pandas in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from sagemaker>=2.110.1) (1.4.2)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from sagemaker>=2.110.1) (4.12.0)\n",
      "Requirement already satisfied: google-pasta in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from sagemaker>=2.110.1) (0.2.0)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from sagemaker>=2.110.1) (0.1.5)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from sagemaker>=2.110.1) (1.0.1)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from sagemaker>=2.110.1) (3.19.1)\n",
      "Requirement already satisfied: boto3<2.0,>=1.20.21 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from sagemaker>=2.110.1) (1.24.87)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from sagemaker>=2.110.1) (21.3)\n",
      "Requirement already satisfied: schema in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from sagemaker>=2.110.1) (0.7.5)\n",
      "Requirement already satisfied: pathos in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from sagemaker>=2.110.1) (0.2.8)\n",
      "Requirement already satisfied: attrs<23,>=20.3.0 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from sagemaker>=2.110.1) (20.3.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from transformers>=4.21.1) (0.11.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from transformers>=4.21.1) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from transformers>=4.21.1) (2021.9.30)\n",
      "Requirement already satisfied: filelock in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from transformers>=4.21.1) (3.8.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from transformers>=4.21.1) (0.10.0)\n",
      "Requirement already satisfied: requests in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from transformers>=4.21.1) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from transformers>=4.21.1) (4.62.3)\n",
      "Requirement already satisfied: multiprocess in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from datasets>=2.2.0) (0.70.12.2)\n",
      "Requirement already satisfied: aiohttp in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from datasets>=2.2.0) (3.8.3)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from datasets>=2.2.0) (8.0.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from datasets>=2.2.0) (2022.1.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from datasets>=2.2.0) (0.18.0)\n",
      "Requirement already satisfied: xxhash in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from datasets>=2.2.0) (2.0.2)\n",
      "Requirement already satisfied: dill<0.3.5 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from datasets>=2.2.0) (0.3.4)\n",
      "Requirement already satisfied: click in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from nltk>=3.4.4) (8.1.3)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.87 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker>=2.110.1) (1.27.87)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker>=2.110.1) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from boto3<2.0,>=1.20.21->sagemaker>=2.110.1) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.9.0->transformers>=4.21.1) (4.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker>=2.110.1) (3.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from packaging>=20.0->sagemaker>=2.110.1) (3.0.4)\n",
      "Requirement already satisfied: six in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker>=2.110.1) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from requests->transformers>=4.21.1) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from requests->transformers>=4.21.1) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from requests->transformers>=4.21.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from requests->transformers>=4.21.1) (3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from aiohttp->datasets>=2.2.0) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from aiohttp->datasets>=2.2.0) (1.6.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from aiohttp->datasets>=2.2.0) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from aiohttp->datasets>=2.2.0) (5.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from aiohttp->datasets>=2.2.0) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from pandas->sagemaker>=2.110.1) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from pandas->sagemaker>=2.110.1) (2.8.2)\n",
      "Requirement already satisfied: pox>=0.3.0 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from pathos->sagemaker>=2.110.1) (0.3.0)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from pathos->sagemaker>=2.110.1) (1.6.6.4)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from schema->sagemaker>=2.110.1) (21.6.0)\n",
      "Installing collected packages: scikit_learn\n",
      "  Attempting uninstall: scikit_learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytorch-forecasting 0.9.1 requires scikit-learn<0.25.0,>=0.24.0, but you have scikit-learn 1.1.2 which is incompatible.\n",
      "multimodal-transformers 0.1.4a0 requires transformers==3.1, but you have transformers 4.22.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed scikit_learn-1.1.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install \"scikit_learn>=1.1.2\" \"sagemaker>=2.110.1\" \"transformers>=4.21.1\" \"datasets>=2.2.0\" \"nltk>=3.4.4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: scikit-learn in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (1.1.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from scikit-learn) (1.20.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/data2/alfred/anaconda3/envs/aws/lib/python3.8/site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure SageMaker version is >= 2.75.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.111.0\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "print(sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::976939723775:role/service-role/AmazonSageMaker-ExecutionRole-20210317T133000\n",
      "sagemaker bucket: sagemaker-us-west-2-976939723775\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket = None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "#role = sagemaker.get_execution_role()\n",
    "role = 'arn:aws:iam::976939723775:role/service-role/AmazonSageMaker-ExecutionRole-20210317T133000'\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "s3_prefix = \"huggingface_serverless/20_newsgroups\"\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Now we'll download a dataset from the web on which we want to train the text classification model.\n",
    "\n",
    "In this example, let us train the text classification model on the [`20 newsgroups dataset`](http://qwone.com/~jason/20Newsgroups/). The `20 newsgroups dataset` consists of 20000 messages taken from 20 Usenet newsgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "data_dir = \"20_newsgroups_bulk\"\n",
    "if os.path.exists(data_dir):  # cleanup existing data folder\n",
    "    shutil.rmtree(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-sample-files/datasets/text/20_newsgroups/20_newsgroups_bulk.tar.gz to ./20_newsgroups_bulk.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://sagemaker-sample-files/datasets/text/20_newsgroups/20_newsgroups_bulk.tar.gz ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism\t\t  rec.autos\t      sci.space\n",
      "comp.graphics\t\t  rec.motorcycles     soc.religion.christian\n",
      "comp.os.ms-windows.misc   rec.sport.baseball  talk.politics.guns\n",
      "comp.sys.ibm.pc.hardware  rec.sport.hockey    talk.politics.mideast\n",
      "comp.sys.mac.hardware\t  sci.crypt\t      talk.politics.misc\n",
      "comp.windows.x\t\t  sci.electronics     talk.religion.misc\n",
      "misc.forsale\t\t  sci.med\n"
     ]
    }
   ],
   "source": [
    "!tar xzf 20_newsgroups_bulk.tar.gz\n",
    "!ls 20_newsgroups_bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 20\n"
     ]
    }
   ],
   "source": [
    "file_list = [os.path.join(data_dir, f) for f in os.listdir(data_dir)]\n",
    "print(\"Number of files:\", len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 19997\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "documents_count = 0\n",
    "for file in file_list:\n",
    "    df = pd.read_csv(file, header=None, names=[\"text\"])\n",
    "    documents_count = documents_count + df.shape[0]\n",
    "print(\"Number of documents:\", documents_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the dataset files and analyze the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['talk.politics.misc',\n",
       " 'rec.autos',\n",
       " 'rec.sport.baseball',\n",
       " 'alt.atheism',\n",
       " 'sci.space',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'comp.graphics',\n",
       " 'rec.sport.hockey',\n",
       " 'talk.politics.mideast',\n",
       " 'sci.crypt',\n",
       " 'talk.politics.guns',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'misc.forsale',\n",
       " 'sci.electronics',\n",
       " 'soc.religion.christian',\n",
       " 'rec.motorcycles',\n",
       " 'sci.med',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_list = [f.split(\"/\")[1] for f in file_list]\n",
    "categories_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the dataset consists of 20 topics, each in different file.\n",
    "\n",
    "Let us inspect the dataset to get some understanding about how the data and the label is provided in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newsgroups: rec.motorcycles\\nPath: cantaloupe....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Newsgroups: rec.motorcycles\\nPath: cantaloupe....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Newsgroups: rec.motorcycles\\nPath: cantaloupe....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Newsgroups: rec.motorcycles\\nPath: cantaloupe....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!rochester!corn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Newsgroups: rec.motorcycles\\nPath: cantaloupe....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Newsgroups: rec.motorcycles\\nPath: cantaloupe....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    Newsgroups: rec.motorcycles\\nPath: cantaloupe....\n",
       "1    Newsgroups: rec.motorcycles\\nPath: cantaloupe....\n",
       "2    Newsgroups: rec.motorcycles\\nPath: cantaloupe....\n",
       "3    Newsgroups: rec.motorcycles\\nPath: cantaloupe....\n",
       "4    Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...\n",
       "..                                                 ...\n",
       "995  Path: cantaloupe.srv.cs.cmu.edu!rochester!corn...\n",
       "996  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...\n",
       "997  Newsgroups: rec.motorcycles\\nPath: cantaloupe....\n",
       "998  Newsgroups: rec.motorcycles\\nPath: cantaloupe....\n",
       "999  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./20_newsgroups_bulk/rec.motorcycles\", header=None, names=[\"text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Newsgroups: rec.motorcycles\\nPath: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!howland.reston.ans.net!agate!linus!linus.mitre.org!mbunix.mitre.org!cookson\\nFrom: cookson@mbunix.mitre.org (Cookson)\\nSubject: Volvo Attack!\\nMessage-ID: <1993Apr21.143403.4644@linus.mitre.org>\\nSender: news@linus.mitre.org (News Service)\\nNntp-Posting-Host: mbunix.mitre.org\\nOrganization: The MITRE Corp., Bedford, Ma.\\nDate: Wed, 21 Apr 1993 14:34:03 GMT\\nLines: 22\\n\\nI was privelged enough to experience my first Volvo attack this weekend.\\n\\nI was last in a line of traffic that was about 6 vehicles long, riding\\ndown Rt. 40 in Groton Ma.  At the side of the road, sitting off on the\\nshoulder was the killer Volvo in question.  No brake lights, no turn signal,\\nnothing.  We were doing about 40 mph and I was following the cage in front\\nof me about 2.5-3 sec. back.  Well, as said cage passes the Volvo, the\\nBrain Dead Idiot (tm) behind the wheel decides that she doesn\\'t need to wait\\nfor me to pass also and turns out perpendicular across both lanes of traffic\\nso that she can turn around...  So I get on the brakes in a effort to not\\nT-bone it, and the horn in an effort to wake the BDI up.  As she finishes\\nthe turn, she looks up at me with a completely blank, uncomprehending\\nstare.\\n\\nWhere can I get rocket launchers for the VFR?\\n\\nDean\\n-- \\n| Dean Cookson / dcookson@mitre.org / 617 271-2714    | DoD #207  AMA #573534 |\\n| The MITRE Corp. Burlington Rd., Bedford, Ma. 01730  | KotNML  /  KotB       |\\n| \"The road is my shepherd and I shall not stop\"      | \\'92 VFR750F           |\\n| -Sam Eliott, Road Hogs MTV 1993                     | \\'88 Bianchi Limited   |\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newsgroups: comp.sys.mac.hardware\\nPath: canta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!crabapple.srv....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Newsgroups: comp.sys.mac.hardware\\nPath: canta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newsgroups: comp.sys.mac.hardware\\nPath: canta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Newsgroups: comp.sys.mac.hardware\\nPath: canta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Xref: cantaloupe.srv.cs.cmu.edu comp.sys.ibm.p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Path: cantaloupe.srv.cs.cmu.edu!crabapple.srv....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Newsgroups: comp.sys.mac.hardware\\nPath: canta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Newsgroups: comp.sys.mac.hardware\\nPath: canta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    Newsgroups: comp.sys.mac.hardware\\nPath: canta...\n",
       "1    Path: cantaloupe.srv.cs.cmu.edu!crabapple.srv....\n",
       "2    Newsgroups: comp.sys.mac.hardware\\nPath: canta...\n",
       "3    Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...\n",
       "4    Newsgroups: comp.sys.mac.hardware\\nPath: canta...\n",
       "..                                                 ...\n",
       "995  Newsgroups: comp.sys.mac.hardware\\nPath: canta...\n",
       "996  Xref: cantaloupe.srv.cs.cmu.edu comp.sys.ibm.p...\n",
       "997  Path: cantaloupe.srv.cs.cmu.edu!crabapple.srv....\n",
       "998  Newsgroups: comp.sys.mac.hardware\\nPath: canta...\n",
       "999  Newsgroups: comp.sys.mac.hardware\\nPath: canta...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./20_newsgroups_bulk/comp.sys.mac.hardware\", header=None, names=[\"text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Newsgroups: comp.sys.mac.hardware\\nPath: cantaloupe.srv.cs.cmu.edu!rochester!udel!gatech!howland.reston.ans.net!agate!headwall.Stanford.EDU!nntp.Stanford.EDU!cmwand\\nFrom: cmwand@leland.Stanford.EDU (Christopher Wand)\\nSubject: Re: Syquest 150 ???\\nMessage-ID: <1993Apr20.043629.21237@leland.Stanford.EDU>\\nSender: news@leland.Stanford.EDU (Mr News)\\nOrganization: DSG, Stanford University, CA 94305, USA\\nReferences: <93759@hydra.gatech.EDU>\\nDistribution: usa\\nDate: Tue, 20 Apr 93 04:36:29 GMT\\nLines: 30\\n\\nIn article <93759@hydra.gatech.EDU> gt8798a@prism.gatech.EDU (Anthony S. Kim) writes:\\n>I remember someone mention about a 150meg syquest.  Has anyone else\\n>heard anything about this?  I\\'d be interested in the cost per megabyte and the\\n>approximate cost of the drive itself and how they compare to the Bernoulli 150.\\n\\nI think you must be talking about the Syquest 105 (code named Mesa I believe).\\nIt is a 3.5\" Winchester technology drive pretty much like the other Syquest\\ndrives in terms of how it works. According to the latest MacLeak, the \\ndrive has a 14.5 ms access time, 1.9 MB/s sustained throughput (these figures\\nare from memory so they could be slightly off, but they give you an idea of\\nperformance nonetheless). The drive was originally released for the PC\\nand just recently was released for the Mac world (don\\'t ask me what the \\ndifferences are) and through they are currently in limited supply, according\\nto a Syquest rep. they are in the process of ramping up for mass production.\\nI have already seen them advertised by a number of manufacturers in MacLeak\\nincluding PLI, MassMicro, ClubMac, and MacWarehouse\\'s PowerUser. The PLI\\nand MassMicro units are priced at just around $1000; the lesser name brands\\nare going for around $750 for an external drive. Cartridges which hold \\n105 MB sell for about $80 each. At these prices, the drives and cartridges\\nare cheaper and better performing than the 88MB drives.\\nCost per megabyte compares favorably with other cartridge drives and Bernoulli\\ndrives, but for large amounts of data optical is still cheaper, and more\\nreliable.  Personally, I\\'m excited by the new drive and look forward to \\ngetting my hands on one.\\n-Chris Wand\\n\\n-- \\n\\n\"Egotism is the anesthetic that dulls the pain of stupidity.\"\\n                                                     - Frank Leahy\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above, there is a single file for each class in the dataset. Each record is just a plain text paragraphs with header, body, footer and quotes. We will need to process them into a suitable data format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "We need to preprocess the dataset to remove the header, footer, quotes, leading/trailing whitespace, extra spaces, tabs, and HTML tags/markups. \n",
    "\n",
    "Download the `nltk` tokenizer and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alfred/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import string\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets._twenty_newsgroups import (\n",
    "    strip_newsgroup_header,\n",
    "    strip_newsgroup_quoting,\n",
    "    strip_newsgroup_footer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following function will remove the header, footer and quotes (of earlier messages in each text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_newsgroup_item(item):\n",
    "    item = strip_newsgroup_header(item)\n",
    "    item = strip_newsgroup_quoting(item)\n",
    "    item = strip_newsgroup_footer(item)\n",
    "    return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will take care of removing leading/trailing whitespace, extra spaces, tabs, and HTML tags/markups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(texts):\n",
    "    final_text_list = []\n",
    "    for text in texts:\n",
    "\n",
    "        # Check if the sentence is a missing value\n",
    "        if isinstance(text, str) == False:\n",
    "            text = \"\"\n",
    "\n",
    "        filtered_sentence = []\n",
    "\n",
    "        # Lowercase\n",
    "        text = text.lower()\n",
    "\n",
    "        # Remove leading/trailing whitespace, extra space, tabs, and HTML tags/markups\n",
    "        text = text.strip()\n",
    "        text = re.sub(\"\\[.*?\\]\", \"\", text)\n",
    "        text = re.sub(\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
    "        text = re.sub(\"<.*?>+\", \"\", text)\n",
    "        text = re.sub(\"[%s]\" % re.escape(string.punctuation), \"\", text)\n",
    "        text = re.sub(\"\\n\", \"\", text)\n",
    "        text = re.sub(\"\\w*\\d\\w*\", \"\", text)\n",
    "\n",
    "        for w in word_tokenize(text):\n",
    "            # We are applying some custom filtering here, feel free to try different things\n",
    "            # Check if it is not numeric\n",
    "            if not w.isnumeric():\n",
    "                filtered_sentence.append(w)\n",
    "        final_string = \" \".join(filtered_sentence)  # final string of cleaned words\n",
    "\n",
    "        final_text_list.append(final_string)\n",
    "\n",
    "    return final_text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will read each of the `20_newsgroups` dataset files, call `strip_newsgroup_item` and `process_text` functions we defined earlier, and then aggregate all data into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/talk.politics.misc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/rec.autos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/rec.sport.baseball\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/alt.atheism\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/sci.space\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/comp.sys.mac.hardware\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/comp.windows.x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/comp.graphics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/rec.sport.hockey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/talk.politics.mideast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/sci.crypt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/talk.politics.guns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/comp.os.ms-windows.misc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/comp.sys.ibm.pc.hardware\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/misc.forsale\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/sci.electronics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/soc.religion.christian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/rec.motorcycles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/sci.med\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20_newsgroups_bulk/talk.religion.misc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-163c8b3745cc>:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_categories_df = all_categories_df.append(df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "all_categories_df = pd.DataFrame()\n",
    "\n",
    "for file in file_list:\n",
    "    print(f\"Processing {file}\")\n",
    "    label = file.split(\"/\")[1]\n",
    "    df = pd.read_csv(file, header=None, names=[\"text\"])\n",
    "    df[\"text\"] = df[\"text\"].apply(strip_newsgroup_item)\n",
    "    df[\"text\"] = process_text(df[\"text\"].tolist())\n",
    "    df[\"label\"] = label\n",
    "    all_categories_df = all_categories_df.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect how many categories there are in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "talk.politics.misc          1000\n",
       "rec.autos                   1000\n",
       "sci.med                     1000\n",
       "rec.motorcycles             1000\n",
       "sci.electronics             1000\n",
       "misc.forsale                1000\n",
       "comp.sys.ibm.pc.hardware    1000\n",
       "comp.os.ms-windows.misc     1000\n",
       "talk.politics.guns          1000\n",
       "sci.crypt                   1000\n",
       "talk.politics.mideast       1000\n",
       "rec.sport.hockey            1000\n",
       "comp.graphics               1000\n",
       "comp.windows.x              1000\n",
       "comp.sys.mac.hardware       1000\n",
       "sci.space                   1000\n",
       "alt.atheism                 1000\n",
       "rec.sport.baseball          1000\n",
       "talk.religion.misc          1000\n",
       "soc.religion.christian       997\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_categories_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our dataset there are 20 categories which is too much, so we will combine the sub-categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace to politics\n",
    "all_categories_df[\"label\"].replace(\n",
    "    {\n",
    "        \"talk.politics.misc\": \"politics\",\n",
    "        \"talk.politics.guns\": \"politics\",\n",
    "        \"talk.politics.mideast\": \"politics\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# replace to recreational\n",
    "all_categories_df[\"label\"].replace(\n",
    "    {\n",
    "        \"rec.sport.hockey\": \"recreational\",\n",
    "        \"rec.sport.baseball\": \"recreational\",\n",
    "        \"rec.autos\": \"recreational\",\n",
    "        \"rec.motorcycles\": \"recreational\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# replace to religion\n",
    "all_categories_df[\"label\"].replace(\n",
    "    {\n",
    "        \"soc.religion.christian\": \"religion\",\n",
    "        \"talk.religion.misc\": \"religion\",\n",
    "        \"alt.atheism\": \"religion\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# replace to computer\n",
    "all_categories_df[\"label\"].replace(\n",
    "    {\n",
    "        \"comp.windows.x\": \"computer\",\n",
    "        \"comp.sys.ibm.pc.hardware\": \"computer\",\n",
    "        \"comp.os.ms-windows.misc\": \"computer\",\n",
    "        \"comp.graphics\": \"computer\",\n",
    "        \"comp.sys.mac.hardware\": \"computer\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "# replace to sales\n",
    "all_categories_df[\"label\"].replace({\"misc.forsale\": \"sales\"}, inplace=True)\n",
    "\n",
    "# replace to science\n",
    "all_categories_df[\"label\"].replace(\n",
    "    {\n",
    "        \"sci.crypt\": \"science\",\n",
    "        \"sci.electronics\": \"science\",\n",
    "        \"sci.med\": \"science\",\n",
    "        \"sci.space\": \"science\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are left with 6 categories, which is much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "computer        5000\n",
       "recreational    4000\n",
       "science         4000\n",
       "politics        3000\n",
       "religion        2997\n",
       "sales           1000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_categories_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate number of words for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>too many</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when mcmanus says we have the worlds best medi...</td>\n",
       "      <td>politics</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im addicted to chocolate myself</td>\n",
       "      <td>politics</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wow does this mean out of homosexuals will be ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if you cant convict em dont bust em plea bargi...</td>\n",
       "      <td>politics</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label  word_count\n",
       "0                                           too many  politics           2\n",
       "1  when mcmanus says we have the worlds best medi...  politics         819\n",
       "2                    im addicted to chocolate myself  politics           5\n",
       "3  wow does this mean out of homosexuals will be ...  politics          26\n",
       "4  if you cant convict em dont bust em plea bargi...  politics          18"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_categories_df[\"word_count\"] = all_categories_df[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "all_categories_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get basic statistics about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19997.000000\n",
       "mean       159.346102\n",
       "std        434.479067\n",
       "min          0.000000\n",
       "25%         37.000000\n",
       "50%         74.000000\n",
       "75%        148.000000\n",
       "max      11351.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_categories_df[\"word_count\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the mean value is around 159 words. However, there are outliers, such as a text with 11351 words. This can make it harder for the model to result in good performance. We will take care to drop those rows.\n",
    "\n",
    "Let's drop empty rows first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "no_text = all_categories_df[all_categories_df[\"word_count\"] == 0]\n",
    "print(len(no_text))\n",
    "\n",
    "# drop these rows\n",
    "all_categories_df.drop(no_text.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the rows that are longer than 256 words, as it is a length close to the mean value of the word count. This is done to make it easy for the model to train without outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2409\n"
     ]
    }
   ],
   "source": [
    "long_text = all_categories_df[all_categories_df[\"word_count\"] > 256]\n",
    "print(len(long_text))\n",
    "\n",
    "# drop these rows\n",
    "all_categories_df.drop(long_text.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "computer        4659\n",
       "recreational    3675\n",
       "science         3506\n",
       "politics        2370\n",
       "religion        2349\n",
       "sales            939\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_categories_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get basic statistics about the dataset after our outliers fixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    17498.000000\n",
       "mean        79.797348\n",
       "std         59.636188\n",
       "min          1.000000\n",
       "25%         33.000000\n",
       "50%         64.000000\n",
       "75%        113.000000\n",
       "max        256.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_categories_df[\"word_count\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much more balanced.\n",
    "\n",
    "Now we drop the `word_count` columns as we will not need it anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories_df.drop(columns=\"word_count\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>too many</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im addicted to chocolate myself</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wow does this mean out of homosexuals will be ...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if you cant convict em dont bust em plea bargi...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>so it will be interesting to see the reaction ...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19991</th>\n",
       "      <td>this is cute but i see no statement telling me...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19992</th>\n",
       "      <td>im confused could you restate what yer saying ...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>not true consider the case of a coin i flip it...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>contradicting itself on facts for example</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>in god whose word i praise in god i trust i wi...</td>\n",
       "      <td>religion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17498 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label\n",
       "0                                               too many  politics\n",
       "2                        im addicted to chocolate myself  politics\n",
       "3      wow does this mean out of homosexuals will be ...  politics\n",
       "4      if you cant convict em dont bust em plea bargi...  politics\n",
       "5      so it will be interesting to see the reaction ...  politics\n",
       "...                                                  ...       ...\n",
       "19991  this is cute but i see no statement telling me...  religion\n",
       "19992  im confused could you restate what yer saying ...  religion\n",
       "19994  not true consider the case of a coin i flip it...  religion\n",
       "19995          contradicting itself on facts for example  religion\n",
       "19996  in god whose word i praise in god i trust i wi...  religion\n",
       "\n",
       "[17498 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_categories_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert categorical label to integer number, in order to prepare the dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['politics', 'recreational', 'religion', 'science', 'computer', 'sales']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = all_categories_df[\"label\"].unique().tolist()\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories.index(\"recreational\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories_df[\"label\"] = all_categories_df[\"label\"].apply(lambda x: categories.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    4659\n",
       "1    3675\n",
       "3    3506\n",
       "0    2370\n",
       "2    2349\n",
       "5     939\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_categories_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We partition the dataset into 80% training and 20% validation set and save to `csv` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(all_categories_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the label distribution in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    3704\n",
       "1    2977\n",
       "3    2812\n",
       "2    1884\n",
       "0    1872\n",
       "5     749\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the label distribution in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    955\n",
       "1    698\n",
       "3    694\n",
       "0    498\n",
       "2    465\n",
       "5    190\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization \n",
    "\n",
    "A tokenizer is in charge of preparing the inputs for a model. The library contains tokenizers for all the models. Most of the tokenizers are available in two flavors: a full python implementation and a “Fast” implementation based on the Rust library [tokenizers](https://github.com/huggingface/tokenizers). The “Fast” implementations allows:\n",
    "\n",
    " - A significant speed-up in particular when doing batched tokenization.\n",
    " - Additional methods to map between the original string (character and words) and the token space (e.g. getting the index of the token comprising a given character or the span of characters corresponding to a given token). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer used in preprocessing\n",
    "tokenizer_name = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f67e64ebb64bba82a7ecd5526cb8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa26a05d226341448652e893a9ef8694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550925ae468442e7a4606a1b0fa95a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8267599717374f5391df05d1dc391d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# download tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train and test datasets\n",
    "\n",
    "Let's create a [Dataset](https://huggingface.co/docs/datasets/loading_datasets.html) from our local `csv` files for training and test we saved earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-a41e360c022e15a5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/alfred/.cache/huggingface/datasets/csv/default-a41e360c022e15a5/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5943662a24d4a2c82eba7c22686d852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5201196ddc554927b9ad2e274524d711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/alfred/.cache/huggingface/datasets/csv/default-a41e360c022e15a5/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e535f6bc590486d84eca266b2a9b0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"csv\", data_files={\"train\": \"train.csv\", \"test\": \"test.csv\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 13998\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 3500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 13998\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'the is a week backorder but they are shipping', 'label': 4}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 3500\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'james sledd asks what is the nature of eternal life how can we as mortals locked into spacetime conceive of it if the best we can do is metaphoranalogy then what is the best metaphorc s lewiss essay the weight of glory deals with this question irecommend it enthusiastically you might also read the chapter onheaven in his book the problem of pain he gives a fictionaltreatment in his book the great divorce i have found all of thesevery helpfulyou might also be helped by the treatment in dantes divine comedyheaven occupies the last third of the poem but i can not imaginereading it other than from the beginning i urge you to use thetranslation by dorothy l sayers available from penguin paperbacks',\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer helper function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize train and test datasets\n",
    "\n",
    "Let's tokenize the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5939752ae693435494c5650d0e6ebc6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tokenize the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a18c4e83913443da82be418333d0da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = test_dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set format for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading data to `sagemaker_session_bucket`\n",
    "\n",
    "After we processed the datasets, we are going to upload it to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-976939723775/huggingface_serverless/20_newsgroups/train\n",
      "s3://sagemaker-us-west-2-976939723775/huggingface_serverless/20_newsgroups/test\n"
     ]
    }
   ],
   "source": [
    "import botocore\n",
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "s3 = S3FileSystem()\n",
    "\n",
    "# save train_dataset to s3\n",
    "training_input_path = f\"s3://{sess.default_bucket()}/{s3_prefix}/train\"\n",
    "train_dataset.save_to_disk(training_input_path, fs=s3)\n",
    "\n",
    "# save test_dataset to s3\n",
    "test_input_path = f\"s3://{sess.default_bucket()}/{s3_prefix}/test\"\n",
    "test_dataset.save_to_disk(test_input_path, fs=s3)\n",
    "\n",
    "print(training_input_path)\n",
    "print(test_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the HuggingFace model for supervised text classification\n",
    "\n",
    "In order to create a sagemaker training job we need a `HuggingFace` Estimator. The Estimator handles end-to-end Amazon SageMaker training and deployment tasks. In an Estimator we define, which fine-tuning script should be used as `entry_point`, which `instance_type` should be used, which `hyperparameters` are passed in .....\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "huggingface_estimator = HuggingFace(entry_point='train.py',\n",
    "                            source_dir='./code',\n",
    "                            instance_type='ml.p3.2xlarge',\n",
    "                            instance_count=1,\n",
    "                            volume_size=256,\n",
    "                            role=role,\n",
    "                            transformers_version='4.6',\n",
    "                            pytorch_version='1.7',\n",
    "                            py_version='py36',\n",
    "                            hyperparameters = {'epochs': 1,\n",
    "                                               'model_name':'distilbert-base-uncased',\n",
    "                                               'num_labels': 6\n",
    "                                              })\n",
    "```\n",
    "\n",
    "When we create a SageMaker training job, SageMaker takes care of starting and managing all the required ec2 instances for us with the `huggingface` container, uploads the provided fine-tuning script `train.py` and downloads the data from our `sagemaker_session_bucket` into the container at `/opt/ml/input/data`. Then, it starts the training job by running. \n",
    "\n",
    "```python\n",
    "/opt/conda/bin/python train.py --epochs 1 --model_name distilbert-base-uncased --num_labels 6\n",
    "```\n",
    "\n",
    "The `hyperparameters` you define in the `HuggingFace` estimator are passed in as named arguments. \n",
    "\n",
    "SageMaker is providing useful properties about the training environment through various environment variables, including the following:\n",
    "\n",
    "* `SM_MODEL_DIR`: A string that represents the path where the training job writes the model artifacts to. After training, artifacts in this directory are uploaded to S3 for model hosting.\n",
    "\n",
    "* `SM_NUM_GPUS`: An integer representing the number of GPUs available to the host.\n",
    "\n",
    "* `SM_CHANNEL_XXXX:` A string that represents the path to the directory that contains the input data for the specified channel. For example, if you specify two input channels in the HuggingFace estimator’s fit call, named `train` and `test`, the environment variables `SM_CHANNEL_TRAIN` and `SM_CHANNEL_TEST` are set.\n",
    "\n",
    "\n",
    "To run your training job locally you can define `instance_type='local'` or `instance_type='local-gpu'` for `gpu` usage. _Note: this does not work within SageMaker Studio_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a metric_definition dictionary that contains regex-based definitions that will be used to parse the job logs and extract metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {\"Name\": \"loss\", \"Regex\": \"'loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"learning_rate\", \"Regex\": \"'learning_rate': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_loss\", \"Regex\": \"'eval_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_accuracy\", \"Regex\": \"'eval_accuracy': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_f1\", \"Regex\": \"'eval_f1': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_precision\", \"Regex\": \"'eval_precision': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_recall\", \"Regex\": \"'eval_recall': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_runtime\", \"Regex\": \"'eval_runtime': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\n",
    "        \"Name\": \"eval_samples_per_second\",\n",
    "        \"Regex\": \"'eval_samples_per_second': ([0-9]+(.|e\\-)[0-9]+),?\",\n",
    "    },\n",
    "    {\"Name\": \"epoch\", \"Regex\": \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Estimator and start a training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters = {\"epochs\": 3, \"model_name\": \"distilbert-base-uncased\", \"num_labels\": 6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define the SageMaker `HuggingFace` estimator with resource configurations and hyperparameters to train Text Classification on `20 newsgroups` dataset, running on a `p3.2xlarge` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"./\",\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    instance_count=1,\n",
    "    volume_size=256,\n",
    "    role=role,\n",
    "    transformers_version=\"4.10\",\n",
    "    pytorch_version=\"1.9\",\n",
    "    py_version=\"py38\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=metric_definitions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-05 23:17:18 Starting - Starting the training job...ProfilerReport-1665011838: InProgress\n",
      "...\n",
      "2022-10-05 23:18:19 Starting - Preparing the instances for training......\n",
      "2022-10-05 23:19:13 Downloading - Downloading input data...\n",
      "2022-10-05 23:19:43 Training - Downloading the training image...........................\n",
      "2022-10-05 23:24:19 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-10-05 23:24:23,412 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-10-05 23:24:23,440 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-10-05 23:24:23,449 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-10-05 23:24:25,074 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 3,\n",
      "        \"model_name\": \"distilbert-base-uncased\",\n",
      "        \"num_labels\": 6\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2022-10-05-23-17-12-026\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-976939723775/huggingface-pytorch-training-2022-10-05-23-17-12-026/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":3,\"model_name\":\"distilbert-base-uncased\",\"num_labels\":6}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-976939723775/huggingface-pytorch-training-2022-10-05-23-17-12-026/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":3,\"model_name\":\"distilbert-base-uncased\",\"num_labels\":6},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"huggingface-pytorch-training-2022-10-05-23-17-12-026\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-976939723775/huggingface-pytorch-training-2022-10-05-23-17-12-026/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"3\",\"--model_name\",\"distilbert-base-uncased\",\"--num_labels\",\"6\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=3\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=distilbert-base-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_LABELS=6\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 train.py --epochs 3 --model_name distilbert-base-uncased --num_labels 6\u001b[0m\n",
      "\u001b[34m2022-10-05 23:24:33,123 - __main__ - INFO -  loaded train_dataset length is: 13998\u001b[0m\n",
      "\u001b[34m2022-10-05 23:24:33,124 - __main__ - INFO -  loaded test_dataset length is: 3500\u001b[0m\n",
      "\u001b[34m2022-10-05 23:24:33,389 - filelock - INFO - Lock 139966066213360 acquired on /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333.lock\u001b[0m\n",
      "\u001b[34m2022-10-05 23:24:33,666 - filelock - INFO - Lock 139966066213360 released on /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333.lock\u001b[0m\n",
      "\u001b[34m2022-10-05 23:24:33,973 - filelock - INFO - Lock 139966012364400 acquired on /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a.lock\u001b[0m\n",
      "\u001b[34m2022-10-05 23:24:38,101 - filelock - INFO - Lock 139966012364400 released on /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a.lock\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2022-10-05 23:24:39,242 - filelock - INFO - Lock 139966005807280 acquired on /root/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\u001b[0m\n",
      "\u001b[34m2022-10-05 23:24:39,515 - filelock - INFO - Lock 139966005807280 released on /root/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\u001b[0m\n",
      "\u001b[34m2022-10-05 23:24:40,328 - filelock - INFO - Lock 139966005697936 acquired on /root/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\u001b[0m\n",
      "\u001b[34m2022-10-05 23:24:40,860 - filelock - INFO - Lock 139966005697936 released on /root/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\u001b[0m\n",
      "\u001b[34m2022-10-05 23:24:41,133 - filelock - INFO - Lock 139966005697888 acquired on /root/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\u001b[0m\n",
      "\u001b[34m2022-10-05 23:24:41,929 - filelock - INFO - Lock 139966005697888 released on /root/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\u001b[0m\n",
      "\u001b[34mThe following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 13998\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1314\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:47.752 algo-1:29 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:47.889 algo-1:29 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:47.890 algo-1:29 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:47.890 algo-1:29 INFO hook.py:200] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:47.891 algo-1:29 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:47.891 algo-1:29 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.061 algo-1:29 INFO hook.py:591] name:distilbert.embeddings.word_embeddings.weight count_params:23440896\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.061 algo-1:29 INFO hook.py:591] name:distilbert.embeddings.position_embeddings.weight count_params:393216\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.061 algo-1:29 INFO hook.py:591] name:distilbert.embeddings.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.062 algo-1:29 INFO hook.py:591] name:distilbert.embeddings.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.062 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.062 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.062 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.062 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.062 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.062 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.062 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.062 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.0.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.062 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.0.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.062 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.0.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.063 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.063 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.063 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.063 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.0.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.063 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.0.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.063 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.0.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.063 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.063 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.063 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.063 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.063 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.063 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.064 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.064 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.1.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.064 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.1.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.064 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.1.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.064 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.064 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.064 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.064 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.1.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.064 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.1.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.064 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.1.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.064 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.064 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.065 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.065 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.065 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.065 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.065 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.065 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.2.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.065 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.2.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.065 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.2.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.065 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.065 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.065 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.066 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.2.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.066 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.2.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.066 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.2.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.066 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.066 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.066 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.066 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.066 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.066 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.066 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.066 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.3.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.067 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.3.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.067 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.3.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.067 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.067 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.067 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.067 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.3.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.067 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.3.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.067 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.3.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.067 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.067 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.068 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.068 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.068 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.068 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.068 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.068 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.4.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.068 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.4.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.068 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.4.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.068 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.068 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.068 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.068 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.4.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.069 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.4.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.069 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.4.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.069 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.q_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.069 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.q_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.069 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.k_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.069 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.k_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.069 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.v_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.069 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.v_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.069 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.out_lin.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.069 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.5.attention.out_lin.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.069 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.5.sa_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.069 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.5.sa_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.070 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.070 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin1.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.070 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.070 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.5.ffn.lin2.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.070 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.5.output_layer_norm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.070 algo-1:29 INFO hook.py:591] name:distilbert.transformer.layer.5.output_layer_norm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.070 algo-1:29 INFO hook.py:591] name:pre_classifier.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.070 algo-1:29 INFO hook.py:591] name:pre_classifier.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.070 algo-1:29 INFO hook.py:591] name:classifier.weight count_params:4608\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.070 algo-1:29 INFO hook.py:591] name:classifier.bias count_params:6\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.070 algo-1:29 INFO hook.py:593] Total Trainable Params: 66958086\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.071 algo-1:29 INFO hook.py:424] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-10-05 23:24:48.074 algo-1:29 INFO hook.py:488] Hook is writing from the hook with pid: 29\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 3500\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5277383923530579, 'eval_accuracy': 0.8177142857142857, 'eval_runtime': 17.7795, 'eval_samples_per_second': 196.856, 'eval_steps_per_second': 3.093, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m{'loss': 0.8729, 'learning_rate': 5e-05, 'epoch': 1.14}\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-500\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-500/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-500/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-500/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-500/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 3500\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.5065261125564575, 'eval_accuracy': 0.8328571428571429, 'eval_runtime': 17.7159, 'eval_samples_per_second': 197.562, 'eval_steps_per_second': 3.105, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m{'loss': 0.3886, 'learning_rate': 1.928746928746929e-05, 'epoch': 2.28}\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model/checkpoint-1000\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-1000/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-1000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-1000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-1000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 3500\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.4940354824066162, 'eval_accuracy': 0.8485714285714285, 'eval_runtime': 17.7255, 'eval_samples_per_second': 197.455, 'eval_steps_per_second': 3.103, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34m{'train_runtime': 685.8653, 'train_samples_per_second': 61.228, 'train_steps_per_second': 1.916, 'train_loss': 0.5336472672414562, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 3500\n",
      "  Batch size = 64\u001b[0m\n",
      "\n",
      "2022-10-05 23:36:46 Uploading - Uploading generated training model\u001b[34m***** Eval results *****\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/1.42k [00:00<?, ?B/s]#015Downloading: 3.21kB [00:00, 3.11MB/s]                   \u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 483/483 [00:00<00:00, 539kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]#015Downloading:   2%|▏         | 5.31M/268M [00:00<00:04, 53.1MB/s]#015Downloading:   4%|▍         | 10.9M/268M [00:00<00:04, 54.8MB/s]#015Downloading:   6%|▌         | 16.6M/268M [00:00<00:04, 55.7MB/s]#015Downloading:   8%|▊         | 22.3M/268M [00:00<00:04, 56.1MB/s]#015Downloading:  11%|█         | 28.2M/268M [00:00<00:04, 57.4MB/s]#015Downloading:  13%|█▎        | 35.2M/268M [00:00<00:03, 61.5MB/s]#015Downloading:  16%|█▌        | 42.3M/268M [00:00<00:03, 64.6MB/s]#015Downloading:  18%|█▊        | 49.3M/268M [00:00<00:03, 66.3MB/s]#015Downloading:  21%|██        | 56.3M/268M [00:00<00:03, 67.6MB/s]#015Downloading:  24%|██▎       | 63.2M/268M [00:01<00:03, 68.1MB/s]#015Downloading:  26%|██▌       | 70.1M/268M [00:01<00:02, 66.6MB/s]#015Downloading:  29%|██▉       | 77.1M/268M [00:01<00:02, 67.7MB/s]#015Downloading:  31%|███▏      | 84.2M/268M [00:01<00:02, 68.7MB/s]#015Downloading:  34%|███▍      | 91.1M/268M [00:01<00:02, 64.9MB/s]#015Downloading:  36%|███▋      | 97.6M/268M [00:01<00:02, 62.5MB/s]#015Downloading:  39%|███▉      | 104M/268M [00:01<00:02, 60.9MB/s] #015Downloading:  41%|████      | 110M/268M [00:01<00:02, 60.6MB/s]#015Downloading:  44%|████▎     | 117M/268M [00:01<00:02, 63.0MB/s]#015Downloading:  46%|████▋     | 124M/268M [00:01<00:02, 65.0MB/s]#015Downloading:  49%|████▉     | 131M/268M [00:02<00:02, 66.5MB/s]#015Downloading:  52%|█████▏    | 138M/268M [00:02<00:01, 67.8MB/s]#015Downloading:  54%|█████▍    | 145M/268M [00:02<00:01, 68.7MB/s]#015Downloading:  57%|█████▋    | 152M/268M [00:02<00:01, 69.2MB/s]#015Downloading:  59%|█████▉    | 159M/268M [00:02<00:01, 69.4MB/s]#015Downloading:  62%|██████▏   | 166M/268M [00:02<00:01, 69.4MB/s]#015Downloading:  65%|██████▍   | 173M/268M [00:02<00:01, 67.3MB/s]#015Downloading:  67%|██████▋   | 180M/268M [00:02<00:01, 68.1MB/s]#015Downloading:  70%|██████▉   | 187M/268M [00:02<00:01, 68.9MB/s]#015Downloading:  72%|███████▏  | 194M/268M [00:02<00:01, 66.8MB/s]#015Downloading:  75%|███████▍  | 201M/268M [00:03<00:01, 63.5MB/s]#015Downloading:  77%|███████▋  | 207M/268M [00:03<00:00, 61.5MB/s]#015Downloading:  80%|███████▉  | 214M/268M [00:03<00:00, 63.9MB/s]#015Downloading:  83%|████████▎ | 221M/268M [00:03<00:00, 65.7MB/s]#015Downloading:  85%|████████▌ | 228M/268M [00:03<00:00, 67.0MB/s]#015Downloading:  88%|████████▊ | 235M/268M [00:03<00:00, 68.2MB/s]#015Downloading:  90%|█████████ | 242M/268M [00:03<00:00, 68.8MB/s]#015Downloading:  93%|█████████▎| 249M/268M [00:03<00:00, 69.5MB/s]#015Downloading:  96%|█████████▌| 256M/268M [00:03<00:00, 69.8MB/s]#015Downloading:  98%|█████████▊| 264M/268M [00:04<00:00, 70.1MB/s]#015Downloading: 100%|██████████| 268M/268M [00:04<00:00, 65.9MB/s]\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 30.7kB/s]\u001b[0m\n",
      "\u001b[34m2022-10-05 23:36:32,354 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]#015Downloading:  37%|███▋      | 85.0k/232k [00:00<00:00, 675kB/s]#015Downloading: 100%|██████████| 232k/232k [00:00<00:00, 1.21MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]#015Downloading:   9%|▉         | 41.0k/466k [00:00<00:01, 322kB/s]#015Downloading:  33%|███▎      | 152k/466k [00:00<00:00, 642kB/s] #015Downloading:  64%|██████▍   | 299k/466k [00:00<00:00, 872kB/s]#015Downloading:  96%|█████████▌| 446k/466k [00:00<00:00, 985kB/s]#015Downloading: 100%|██████████| 466k/466k [00:00<00:00, 908kB/s]\u001b[0m\n",
      "\u001b[34mThe following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\u001b[0m\n",
      "\u001b[34m***** Running training *****\n",
      "  Num examples = 13998\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1314\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/1314 [00:00<?, ?it/s]#015  0%|          | 1/1314 [00:02<1:01:47,  2.82s/it]#015  0%|          | 2/1314 [00:03<31:38,  1.45s/it]  #015  0%|          | 3/1314 [00:03<21:58,  1.01s/it]#015  0%|          | 4/1314 [00:04<17:20,  1.26it/s]#015  0%|          | 5/1314 [00:04<14:46,  1.48it/s]#015  0%|          | 6/1314 [00:05<13:13,  1.65it/s]#015  1%|          | 7/1314 [00:05<12:14,  1.78it/s]#015  1%|          | 8/1314 [00:06<11:35,  1.88it/s]#015  1%|          | 9/1314 [00:06<11:09,  1.95it/s]#015  1%|          | 10/1314 [00:07<10:53,  2.00it/s]#015  1%|          | 11/1314 [00:07<10:42,  2.03it/s]#015  1%|          | 12/1314 [00:08<10:37,  2.04it/s]#015  1%|          | 13/1314 [00:08<10:29,  2.07it/s]#015  1%|          | 14/1314 [00:08<10:23,  2.09it/s]#015  1%|          | 15/1314 [00:09<10:20,  2.09it/s]#015  1%|          | 16/1314 [00:09<10:19,  2.10it/s]#015  1%|▏         | 17/1314 [00:10<10:17,  2.10it/s]#015  1%|▏         | 18/1314 [00:10<10:15,  2.11it/s]#015  1%|▏         | 19/1314 [00:11<10:13,  2.11it/s]#015  2%|▏         | 20/1314 [00:11<10:13,  2.11it/s]#015  2%|▏         | 21/1314 [00:12<10:14,  2.10it/s]#015  2%|▏         | 22/1314 [00:12<10:14,  2.10it/s]#015  2%|▏         | 23/1314 [00:13<10:11,  2.11it/s]#015  2%|▏         | 24/1314 [00:13<10:09,  2.11it/s]#015  2%|▏         | 25/1314 [00:14<10:09,  2.12it/s]#015  2%|▏         | 26/1314 [00:14<10:12,  2.10it/s]#015  2%|▏         | 27/1314 [00:15<10:13,  2.10it/s]#015  2%|▏         | 28/1314 [00:15<10:13,  2.10it/s]#015  2%|▏         | 29/1314 [00:16<10:13,  2.09it/s]#015  2%|▏         | 30/1314 [00:16<10:10,  2.10it/s]#015  2%|▏         | 31/1314 [00:17<10:09,  2.10it/s]#015  2%|▏         | 32/1314 [00:17<10:09,  2.10it/s]#015  3%|▎         | 33/1314 [00:17<10:06,  2.11it/s]#015  3%|▎         | 34/1314 [00:18<10:04,  2.12it/s]#015  3%|▎         | 35/1314 [00:18<10:03,  2.12it/s]#015  3%|▎         | 36/1314 [00:19<10:01,  2.12it/s]#015  3%|▎         | 37/1314 [00:19<10:00,  2.13it/s]#015  3%|▎         | 38/1314 [00:20<10:02,  2.12it/s]#015  3%|▎         | 39/1314 [00:20<10:02,  2.12it/s]#015  3%|▎         | 40/1314 [00:21<10:03,  2.11it/s]#015  3%|▎         | 41/1314 [00:21<10:04,  2.11it/s]#015  3%|▎         | 42/1314 [00:22<10:05,  2.10it/s]#015  3%|▎         | 43/1314 [00:22<10:05,  2.10it/s]#015  3%|▎         | 44/1314 [00:23<10:03,  2.11it/s]#015  3%|▎         | 45/1314 [00:23<10:01,  2.11it/s]#015  4%|▎         | 46/1314 [00:24<10:00,  2.11it/s]#015  4%|▎         | 47/1314 [00:24<09:58,  2.12it/s]#015  4%|▎         | 48/1314 [00:25<09:57,  2.12it/s]#015  4%|▎         | 49/1314 [00:25<09:58,  2.11it/s]#015  4%|▍         | 50/1314 [00:26<09:59,  2.11it/s]#015  4%|▍         | 51/1314 [00:26<10:00,  2.10it/s]#015  4%|▍         | 52/1314 [00:26<10:00,  2.10it/s]#015  4%|▍         | 53/1314 [00:27<09:59,  2.10it/s]#015  4%|▍         | 54/1314 [00:27<09:57,  2.11it/s]#015  4%|▍         | 55/1314 [00:28<09:55,  2.11it/s]#015  4%|▍         | 56/1314 [00:28<09:55,  2.11it/s]#015  4%|▍         | 57/1314 [00:29<09:57,  2.10it/s]#015  4%|▍         | 58/1314 [00:29<09:57,  2.10it/s]#015  4%|▍         | 59/1314 [00:30<09:55,  2.11it/s]#015  5%|▍         | 60/1314 [00:30<09:53,  2.11it/s]#015  5%|▍         | 61/1314 [00:31<09:52,  2.11it/s]#015  5%|▍         | 62/1314 [00:31<09:54,  2.11it/s]#015  5%|▍         | 63/1314 [00:32<09:53,  2.11it/s]#015  5%|▍         | 64/1314 [00:32<09:54,  2.10it/s]#015  5%|▍         | 65/1314 [00:33<09:54,  2.10it/s]#015  5%|▌         | 66/1314 [00:33<09:52,  2.11it/s]#015  5%|▌         | 67/1314 [00:34<09:53,  2.10it/s]#015  5%|▌         | 68/1314 [00:34<09:51,  2.11it/s]#015  5%|▌         | 69/1314 [00:35<09:51,  2.11it/s]#015  5%|▌         | 70/1314 [00:35<09:52,  2.10it/s]#015  5%|▌         | 71/1314 [00:36<09:51,  2.10it/s]#015  5%|▌         | 72/1314 [00:36<09:51,  2.10it/s]#015  6%|▌         | 73/1314 [00:36<09:51,  2.10it/s]#015  6%|▌         | 74/1314 [00:37<09:51,  2.10it/s]#015  6%|▌         | 75/1314 [00:37<09:49,  2.10it/s]#015  6%|▌         | 76/1314 [00:38<09:47,  2.11it/s]#015  6%|▌         | 77/1314 [00:38<09:47,  2.11it/s]#015  6%|▌         | 78/1314 [00:39<09:47,  2.10it/s]#015  6%|▌         | 79/1314 [00:39<09:45,  2.11it/s]#015  6%|▌         | 80/1314 [00:40<09:46,  2.11it/s]#015  6%|▌         | 81/1314 [00:40<09:44,  2.11it/s]#015  6%|▌         | 82/1314 [00:41<09:42,  2.11it/s]#015  6%|▋         | 83/1314 [00:41<09:41,  2.12it/s]#015  6%|▋         | 84/1314 [00:42<09:39,  2.12it/s]#015  6%|▋         | 85/1314 [00:42<09:39,  2.12it/s]#015  7%|▋         | 86/1314 [00:43<09:38,  2.12it/s]#015  7%|▋         | 87/1314 [00:43<09:38,  2.12it/s]#015  7%|▋         | 88/1314 [00:44<09:38,  2.12it/s]#015  7%|▋         | 89/1314 [00:44<09:39,  2.11it/s]#015  7%|▋         | 90/1314 [00:45<09:40,  2.11it/s]#015  7%|▋         | 91/1314 [00:45<09:40,  2.11it/s]#015  7%|▋         | 92/1314 [00:45<09:40,  2.10it/s]#015  7%|▋         | 93/1314 [00:46<09:40,  2.10it/s]#015  7%|▋         | 94/1314 [00:46<09:39,  2.10it/s]#015  7%|▋         | 95/1314 [00:47<09:40,  2.10it/s]#015  7%|▋         | 96/1314 [00:47<09:38,  2.10it/s]#015  7%|▋         | 97/1314 [00:48<09:38,  2.10it/s]#015  7%|▋         | 98/1314 [00:48<09:37,  2.11it/s]#015  8%|▊         | 99/1314 [00:49<09:37,  2.10it/s]#015  8%|▊         | 100/1314 [00:49<09:36,  2.11it/s]#015  8%|▊         | 101/1314 [00:50<09:35,  2.11it/s]#015  8%|▊         | 102/1314 [00:50<09:34,  2.11it/s]#015  8%|▊         | 103/1314 [00:51<09:34,  2.11it/s]#015  8%|▊         | 104/1314 [00:51<09:33,  2.11it/s]#015  8%|▊         | 105/1314 [00:52<09:33,  2.11it/s]#015  8%|▊         | 106/1314 [00:52<09:32,  2.11it/s]#015  8%|▊         | 107/1314 [00:53<09:33,  2.10it/s]#015  8%|▊         | 108/1314 [00:53<09:32,  2.11it/s]#015  8%|▊         | 109/1314 [00:54<09:30,  2.11it/s]#015  8%|▊         | 110/1314 [00:54<09:30,  2.11it/s]#015  8%|▊         | 111/1314 [00:54<09:30,  2.11it/s]#015  9%|▊         | 112/1314 [00:55<09:28,  2.11it/s]#015  9%|▊         | 113/1314 [00:55<09:27,  2.12it/s]#015  9%|▊         | 114/1314 [00:56<09:27,  2.12it/s]#015  9%|▉         | 115/1314 [00:56<09:26,  2.12it/s]#015  9%|▉         | 116/1314 [00:57<09:25,  2.12it/s]#015  9%|▉         | 117/1314 [00:57<09:24,  2.12it/s]#015  9%|▉         | 118/1314 [00:58<09:24,  2.12it/s]#015  9%|▉         | 119/1314 [00:58<09:23,  2.12it/s]#015  9%|▉         | 120/1314 [00:59<09:22,  2.12it/s]#015  9%|▉         | 121/1314 [00:59<09:22,  2.12it/s]#015  9%|▉         | 122/1314 [01:00<09:21,  2.12it/s]#015  9%|▉         | 123/1314 [01:00<09:21,  2.12it/s]#015  9%|▉         | 124/1314 [01:01<09:20,  2.12it/s]#015 10%|▉         | 125/1314 [01:01<09:20,  2.12it/s]#015 10%|▉         | 126/1314 [01:02<09:19,  2.12it/s]#015 10%|▉         | 127/1314 [01:02<09:19,  2.12it/s]#015 10%|▉         | 128/1314 [01:02<09:18,  2.12it/s]#015 10%|▉         | 129/1314 [01:03<09:18,  2.12it/s]#015 10%|▉         | 130/1314 [01:03<09:17,  2.12it/s]#015 10%|▉         | 131/1314 [01:04<09:18,  2.12it/s]#015 10%|█         | 132/1314 [01:04<09:18,  2.12it/s]#015 10%|█         | 133/1314 [01:05<09:18,  2.12it/s]#015 10%|█         | 134/1314 [01:05<09:17,  2.12it/s]#015 10%|█         | 135/1314 [01:06<09:18,  2.11it/s]#015 10%|█         | 136/1314 [01:06<09:19,  2.11it/s]#015 10%|█         | 137/1314 [01:07<09:22,  2.09it/s]#015 11%|█         | 138/1314 [01:07<09:21,  2.09it/s]#015 11%|█         | 139/1314 [01:08<09:19,  2.10it/s]#015 11%|█         | 140/1314 [01:08<09:20,  2.09it/s]#015 11%|█         | 141/1314 [01:09<09:20,  2.09it/s]#015 11%|█         | 142/1314 [01:09<09:20,  2.09it/s]#015 11%|█         | 143/1314 [01:10<09:19,  2.09it/s]#015 11%|█         | 144/1314 [01:10<09:18,  2.09it/s]#015 11%|█         | 145/1314 [01:11<09:19,  2.09it/s]#015 11%|█         | 146/1314 [01:11<09:20,  2.09it/s]#015 11%|█         | 147/1314 [01:12<09:19,  2.09it/s]#015 11%|█▏        | 148/1314 [01:12<09:19,  2.08it/s]#015 11%|█▏        | 149/1314 [01:13<09:19,  2.08it/s]#015 11%|█▏        | 150/1314 [01:13<09:19,  2.08it/s]#015 11%|█▏        | 151/1314 [01:13<09:21,  2.07it/s]#015 12%|█▏        | 152/1314 [01:14<09:21,  2.07it/s]#015 12%|█▏        | 153/1314 [01:14<09:18,  2.08it/s]#015 12%|█▏        | 154/1314 [01:15<09:18,  2.08it/s]#015 12%|█▏        | 155/1314 [01:15<09:19,  2.07it/s]#015 12%|█▏        | 156/1314 [01:16<09:18,  2.07it/s]#015 12%|█▏        | 157/1314 [01:16<09:20,  2.07it/s]#015 12%|█▏        | 158/1314 [01:17<09:17,  2.07it/s]#015 12%|█▏        | 159/1314 [01:17<09:16,  2.08it/s]#015 12%|█▏        | 160/1314 [01:18<09:14,  2.08it/s]#015 12%|█▏        | 161/1314 [01:18<09:11,  2.09it/s]#015 12%|█▏        | 162/1314 [01:19<09:11,  2.09it/s]#015 12%|█▏        | 163/1314 [01:19<09:11,  2.09it/s]#015 12%|█▏        | 164/1314 [01:20<09:09,  2.09it/s]#015 13%|█▎        | 165/1314 [01:20<09:09,  2.09it/s]#015 13%|█▎        | 166/1314 [01:21<09:09,  2.09it/s]#015 13%|█▎        | 167/1314 [01:21<09:10,  2.09it/s]#015 13%|█▎        | 168/1314 [01:22<09:09,  2.09it/s]#015 13%|█▎        | 169/1314 [01:22<09:06,  2.09it/s]#015 13%|█▎        | 170/1314 [01:23<09:06,  2.09it/s]#015 13%|█▎        | 171/1314 [01:23<09:07,  2.09it/s]#015 13%|█▎        | 172/1314 [01:24<09:06,  2.09it/s]#015 13%|█▎        | 173/1314 [01:24<09:04,  2.10it/s]#015 13%|█▎        | 174/1314 [01:25<09:03,  2.10it/s]#015 13%|█▎        | 175/1314 [01:25<09:02,  2.10it/s]#015 13%|█▎        | 176/1314 [01:25<09:01,  2.10it/s]#015 13%|█▎        | 177/1314 [01:26<09:02,  2.10it/s]#015 14%|█▎        | 178/1314 [01:26<09:02,  2.09it/s]#015 14%|█▎        | 179/1314 [01:27<09:01,  2.10it/s]#015 14%|█▎        | 180/1314 [01:27<09:00,  2.10it/s]#015 14%|█▍        | 181/1314 [01:28<09:00,  2.09it/s]#015 14%|█▍        | 182/1314 [01:28<09:01,  2.09it/s]#015 14%|█▍        | 183/1314 [01:29<09:01,  2.09it/s]#015 14%|█▍        | 184/1314 [01:29<09:01,  2.09it/s]#015 14%|█▍        | 185/1314 [01:30<09:00,  2.09it/s]#015 14%|█▍        | 186/1314 [01:30<08:57,  2.10it/s]#015 14%|█▍        | 187/1314 [01:31<08:56,  2.10it/s]#015 14%|█▍        | 188/1314 [01:31<08:55,  2.10it/s]#015 14%|█▍        | 189/1314 [01:32<08:54,  2.11it/s]#015 14%|█▍        | 190/1314 [01:32<08:53,  2.11it/s]#015 15%|█▍        | 191/1314 [01:33<08:54,  2.10it/s]#015 15%|█▍        | 192/1314 [01:33<08:55,  2.10it/s]#015 15%|█▍        | 193/1314 [01:34<08:54,  2.10it/s]#015 15%|█▍        | 194/1314 [01:34<08:53,  2.10it/s]#015 15%|█▍        | 195/1314 [01:35<08:52,  2.10it/s]#015 15%|█▍        | 196/1314 [01:35<08:52,  2.10it/s]#015 15%|█▍        | 197/1314 [01:35<08:52,  2.10it/s]#015 15%|█▌        | 198/1314 [01:36<08:51,  2.10it/s]#015 15%|█▌        | 199/1314 [01:36<08:50,  2.10it/s]#015 15%|█▌        | 200/1314 [01:37<08:50,  2.10it/s]#015 15%|█▌        | 201/1314 [01:37<08:50,  2.10it/s]#015 15%|█▌        | 202/1314 [01:38<08:49,  2.10it/s]#015 15%|█▌        | 203/1314 [01:38<08:48,  2.10it/s]#015 16%|█▌        | 204/1314 [01:39<08:47,  2.10it/s]#015 16%|█▌        | 205/1314 [01:39<08:46,  2.11it/s]#015 16%|█▌        | 206/1314 [01:40<08:49,  2.09it/s]#015 16%|█▌        | 207/1314 [01:40<08:48,  2.10it/s]#015 16%|█▌        | 208/1314 [01:41<08:50,  2.08it/s]#015 16%|█▌        | 209/1314 [01:41<08:49,  2.09it/s]#015 16%|█▌        | 210/1314 [01:42<08:47,  2.09it/s]#015 16%|█▌        | 211/1314 [01:42<08:45,  2.10it/s]#015 16%|█▌        | 212/1314 [01:43<08:44,  2.10it/s]#015 16%|█▌        | 213/1314 [01:43<08:45,  2.10it/s]#015 16%|█▋        | 214/1314 [01:44<08:45,  2.09it/s]#015 16%|█▋        | 215/1314 [01:44<08:45,  2.09it/s]#015 16%|█▋        | 216/1314 [01:45<08:45,  2.09it/s]#015 17%|█▋        | 217/1314 [01:45<08:45,  2.09it/s]#015 17%|█▋        | 218/1314 [01:46<08:44,  2.09it/s]#015 17%|█▋        | 219/1314 [01:46<08:43,  2.09it/s]#015 17%|█▋        | 220/1314 [01:46<08:43,  2.09it/s]#015 17%|█▋        | 221/1314 [01:47<08:42,  2.09it/s]#015 17%|█▋        | 222/1314 [01:47<08:42,  2.09it/s]#015 17%|█▋        | 223/1314 [01:48<08:43,  2.08it/s]#015 17%|█▋        | 224/1314 [01:48<08:43,  2.08it/s]#015 17%|█▋        | 225/1314 [01:49<08:42,  2.09it/s]#015 17%|█▋        | 226/1314 [01:49<08:39,  2.09it/s]#015 17%|█▋        | 227/1314 [01:50<08:38,  2.10it/s]#015 17%|█▋        | 228/1314 [01:50<08:39,  2.09it/s]#015 17%|█▋        | 229/1314 [01:51<08:39,  2.09it/s]#015 18%|█▊        | 230/1314 [01:51<08:37,  2.09it/s]#015 18%|█▊        | 231/1314 [01:52<08:38,  2.09it/s]#015 18%|█▊        | 232/1314 [01:52<08:36,  2.09it/s]#015 18%|█▊        | 233/1314 [01:53<08:35,  2.10it/s]#015 18%|█▊        | 234/1314 [01:53<08:35,  2.09it/s]#015 18%|█▊        | 235/1314 [01:54<08:35,  2.09it/s]#015 18%|█▊        | 236/1314 [01:54<08:35,  2.09it/s]#015 18%|█▊        | 237/1314 [01:55<08:36,  2.09it/s]#015 18%|█▊        | 238/1314 [01:55<08:36,  2.08it/s]#015 18%|█▊        | 239/1314 [01:56<08:38,  2.07it/s]#015 18%|█▊        | 240/1314 [01:56<08:35,  2.08it/s]#015 18%|█▊        | 241/1314 [01:57<08:35,  2.08it/s]#015 18%|█▊        | 242/1314 [01:57<08:35,  2.08it/s]#015 18%|█▊        | 243/1314 [01:57<08:35,  2.08it/s]#015 19%|█▊        | 244/1314 [01:58<08:33,  2.08it/s]#015 19%|█▊        | 245/1314 [01:58<08:31,  2.09it/s]#015 19%|█▊        | 246/1314 [01:59<08:30,  2.09it/s]#015 19%|█▉        | 247/1314 [01:59<08:30,  2.09it/s]#015 19%|█▉        | 248/1314 [02:00<08:30,  2.09it/s]#015 19%|█▉        | 249/1314 [02:00<08:28,  2.10it/s]#015 19%|█▉        | 250/1314 [02:01<08:27,  2.10it/s]#015 19%|█▉        | 251/1314 [02:01<08:26,  2.10it/s]#015 19%|█▉        | 252/1314 [02:02<08:27,  2.09it/s]#015 19%|█▉        | 253/1314 [02:02<08:25,  2.10it/s]#015 19%|█▉        | 254/1314 [02:03<08:26,  2.09it/s]#015 19%|█▉        | 255/1314 [02:03<08:26,  2.09it/s]#015 19%|█▉        | 256/1314 [02:04<08:27,  2.09it/s]#015 20%|█▉        | 257/1314 [02:04<08:28,  2.08it/s]#015 20%|█▉        | 258/1314 [02:05<08:27,  2.08it/s]#015 20%|█▉        | 259/1314 [02:05<08:26,  2.08it/s]#015 20%|█▉        | 260/1314 [02:06<08:25,  2.08it/s]#015 20%|█▉        | 261/1314 [02:06<08:24,  2.09it/s]#015 20%|█▉        | 262/1314 [02:07<08:22,  2.09it/s]#015 20%|██        | 263/1314 [02:07<08:22,  2.09it/s]#015 20%|██        | 264/1314 [02:08<08:22,  2.09it/s]#015 20%|██        | 265/1314 [02:08<08:21,  2.09it/s]#015 20%|██        | 266/1314 [02:08<08:22,  2.09it/s]#015 20%|██        | 267/1314 [02:09<08:20,  2.09it/s]#015 20%|██        | 268/1314 [02:09<08:20,  2.09it/s]#015 20%|██        | 269/1314 [02:10<08:20,  2.09it/s]#015 21%|██        | 270/1314 [02:10<08:20,  2.09it/s]#015 21%|██        | 271/1314 [02:11<08:19,  2.09it/s]#015 21%|██        | 272/1314 [02:11<08:18,  2.09it/s]#015 21%|██        | 273/1314 [02:12<08:19,  2.09it/s]#015 21%|██        | 274/1314 [02:12<08:21,  2.07it/s]#015 21%|██        | 275/1314 [02:13<08:20,  2.08it/s]#015 21%|██        | 276/1314 [02:13<08:21,  2.07it/s]#015 21%|██        | 277/1314 [02:14<08:24,  2.05it/s]#015 21%|██        | 278/1314 [02:14<08:23,  2.06it/s]#015 21%|██        | 279/1314 [02:15<08:20,  2.07it/s]#015 21%|██▏       | 280/1314 [02:15<08:34,  2.01it/s]#015 21%|██▏       | 281/1314 [02:16<08:49,  1.95it/s]#015 21%|██▏       | 282/1314 [02:16<09:00,  1.91it/s]#015 22%|██▏       | 283/1314 [02:17<09:10,  1.87it/s]#015 22%|██▏       | 284/1314 [02:17<09:03,  1.89it/s]#015 22%|██▏       | 285/1314 [02:18<08:47,  1.95it/s]#015 22%|██▏       | 286/1314 [02:18<08:35,  1.99it/s]#015 22%|██▏       | 287/1314 [02:19<08:26,  2.03it/s]#015 22%|██▏       | 288/1314 [02:19<08:20,  2.05it/s]#015 22%|██▏       | 289/1314 [02:20<08:16,  2.07it/s]#015 22%|██▏       | 290/1314 [02:20<08:12,  2.08it/s]#015 22%|██▏       | 291/1314 [02:21<08:09,  2.09it/s]#015 22%|██▏       | 292/1314 [02:21<08:07,  2.09it/s]#015 22%|██▏       | 293/1314 [02:22<08:06,  2.10it/s]#015 22%|██▏       | 294/1314 [02:22<08:04,  2.10it/s]#015 22%|██▏       | 295/1314 [02:23<08:03,  2.11it/s]#015 23%|██▎       | 296/1314 [02:23<08:02,  2.11it/s]#015 23%|██▎       | 297/1314 [02:24<08:02,  2.11it/s]#015 23%|██▎       | 298/1314 [02:24<08:01,  2.11it/s]#015 23%|██▎       | 299/1314 [02:25<08:00,  2.11it/s]#015 23%|██▎       | 300/1314 [02:25<08:00,  2.11it/s]#015 23%|██▎       | 301/1314 [02:26<08:00,  2.11it/s]#015 23%|██▎       | 302/1314 [02:26<07:59,  2.11it/s]#015 23%|██▎       | 303/1314 [02:26<07:59,  2.11it/s]#015 23%|██▎       | 304/1314 [02:27<07:58,  2.11it/s]#015 2\u001b[0m\n",
      "\u001b[34m3%|██▎       | 305/1314 [02:27<07:58,  2.11it/s]#015 23%|██▎       | 306/1314 [02:28<07:57,  2.11it/s]#015 23%|██▎       | 307/1314 [02:28<07:57,  2.11it/s]#015 23%|██▎       | 308/1314 [02:29<07:57,  2.11it/s]#015 24%|██▎       | 309/1314 [02:29<07:57,  2.10it/s]#015 24%|██▎       | 310/1314 [02:30<07:56,  2.11it/s]#015 24%|██▎       | 311/1314 [02:30<07:57,  2.10it/s]#015 24%|██▎       | 312/1314 [02:31<07:59,  2.09it/s]#015 24%|██▍       | 313/1314 [02:31<07:59,  2.09it/s]#015 24%|██▍       | 314/1314 [02:32<07:59,  2.09it/s]#015 24%|██▍       | 315/1314 [02:32<08:00,  2.08it/s]#015 24%|██▍       | 316/1314 [02:33<07:59,  2.08it/s]#015 24%|██▍       | 317/1314 [02:33<07:57,  2.09it/s]#015 24%|██▍       | 318/1314 [02:34<07:57,  2.08it/s]#015 24%|██▍       | 319/1314 [02:34<07:57,  2.08it/s]#015 24%|██▍       | 320/1314 [02:35<07:55,  2.09it/s]#015 24%|██▍       | 321/1314 [02:35<07:53,  2.10it/s]#015 25%|██▍       | 322/1314 [02:36<07:52,  2.10it/s]#015 25%|██▍       | 323/1314 [02:36<07:51,  2.10it/s]#015 25%|██▍       | 324/1314 [02:36<07:50,  2.11it/s]#015 25%|██▍       | 325/1314 [02:37<07:49,  2.11it/s]#015 25%|██▍       | 326/1314 [02:37<07:48,  2.11it/s]#015 25%|██▍       | 327/1314 [02:38<07:48,  2.11it/s]#015 25%|██▍       | 328/1314 [02:38<07:47,  2.11it/s]#015 25%|██▌       | 329/1314 [02:39<07:47,  2.11it/s]#015 25%|██▌       | 330/1314 [02:39<07:47,  2.10it/s]#015 25%|██▌       | 331/1314 [02:40<07:48,  2.10it/s]#015 25%|██▌       | 332/1314 [02:40<07:49,  2.09it/s]#015 25%|██▌       | 333/1314 [02:41<07:47,  2.10it/s]#015 25%|██▌       | 334/1314 [02:41<07:46,  2.10it/s]#015 25%|██▌       | 335/1314 [02:42<07:46,  2.10it/s]#015 26%|██▌       | 336/1314 [02:42<07:45,  2.10it/s]#015 26%|██▌       | 337/1314 [02:43<07:45,  2.10it/s]#015 26%|██▌       | 338/1314 [02:43<07:44,  2.10it/s]#015 26%|██▌       | 339/1314 [02:44<07:44,  2.10it/s]#015 26%|██▌       | 340/1314 [02:44<07:44,  2.10it/s]#015 26%|██▌       | 341/1314 [02:45<07:43,  2.10it/s]#015 26%|██▌       | 342/1314 [02:45<07:43,  2.10it/s]#015 26%|██▌       | 343/1314 [02:46<07:43,  2.09it/s]#015 26%|██▌       | 344/1314 [02:46<07:41,  2.10it/s]#015 26%|██▋       | 345/1314 [02:46<07:41,  2.10it/s]#015 26%|██▋       | 346/1314 [02:47<07:40,  2.10it/s]#015 26%|██▋       | 347/1314 [02:47<07:40,  2.10it/s]#015 26%|██▋       | 348/1314 [02:48<07:39,  2.10it/s]#015 27%|██▋       | 349/1314 [02:48<07:39,  2.10it/s]#015 27%|██▋       | 350/1314 [02:49<07:39,  2.10it/s]#015 27%|██▋       | 351/1314 [02:49<07:41,  2.09it/s]#015 27%|██▋       | 352/1314 [02:50<07:40,  2.09it/s]#015 27%|██▋       | 353/1314 [02:50<07:39,  2.09it/s]#015 27%|██▋       | 354/1314 [02:51<07:38,  2.09it/s]#015 27%|██▋       | 355/1314 [02:51<07:37,  2.10it/s]#015 27%|██▋       | 356/1314 [02:52<07:36,  2.10it/s]#015 27%|██▋       | 357/1314 [02:52<07:35,  2.10it/s]#015 27%|██▋       | 358/1314 [02:53<07:36,  2.10it/s]#015 27%|██▋       | 359/1314 [02:53<07:37,  2.09it/s]#015 27%|██▋       | 360/1314 [02:54<07:36,  2.09it/s]#015 27%|██▋       | 361/1314 [02:54<07:36,  2.09it/s]#015 28%|██▊       | 362/1314 [02:55<07:34,  2.09it/s]#015 28%|██▊       | 363/1314 [02:55<07:33,  2.10it/s]#015 28%|██▊       | 364/1314 [02:56<07:32,  2.10it/s]#015 28%|██▊       | 365/1314 [02:56<07:33,  2.09it/s]#015 28%|██▊       | 366/1314 [02:56<07:32,  2.09it/s]#015 28%|██▊       | 367/1314 [02:57<07:32,  2.09it/s]#015 28%|██▊       | 368/1314 [02:57<07:32,  2.09it/s]#015 28%|██▊       | 369/1314 [02:58<07:32,  2.09it/s]#015 28%|██▊       | 370/1314 [02:58<07:32,  2.09it/s]#015 28%|██▊       | 371/1314 [02:59<07:31,  2.09it/s]#015 28%|██▊       | 372/1314 [02:59<07:30,  2.09it/s]#015 28%|██▊       | 373/1314 [03:00<07:31,  2.08it/s]#015 28%|██▊       | 374/1314 [03:00<07:29,  2.09it/s]#015 29%|██▊       | 375/1314 [03:01<07:28,  2.09it/s]#015 29%|██▊       | 376/1314 [03:01<07:28,  2.09it/s]#015 29%|██▊       | 377/1314 [03:02<07:28,  2.09it/s]#015 29%|██▉       | 378/1314 [03:02<07:28,  2.09it/s]#015 29%|██▉       | 379/1314 [03:03<07:28,  2.08it/s]#015 29%|██▉       | 380/1314 [03:03<07:28,  2.08it/s]#015 29%|██▉       | 381/1314 [03:04<07:28,  2.08it/s]#015 29%|██▉       | 382/1314 [03:04<07:28,  2.08it/s]#015 29%|██▉       | 383/1314 [03:05<07:26,  2.09it/s]#015 29%|██▉       | 384/1314 [03:05<07:24,  2.09it/s]#015 29%|██▉       | 385/1314 [03:06<07:23,  2.10it/s]#015 29%|██▉       | 386/1314 [03:06<07:22,  2.10it/s]#015 29%|██▉       | 387/1314 [03:07<07:21,  2.10it/s]#015 30%|██▉       | 388/1314 [03:07<07:20,  2.10it/s]#015 30%|██▉       | 389/1314 [03:08<07:20,  2.10it/s]#015 30%|██▉       | 390/1314 [03:08<07:21,  2.09it/s]#015 30%|██▉       | 391/1314 [03:08<07:20,  2.10it/s]#015 30%|██▉       | 392/1314 [03:09<07:20,  2.09it/s]#015 30%|██▉       | 393/1314 [03:09<07:19,  2.10it/s]#015 30%|██▉       | 394/1314 [03:10<07:18,  2.10it/s]#015 30%|███       | 395/1314 [03:10<07:17,  2.10it/s]#015 30%|███       | 396/1314 [03:11<07:17,  2.10it/s]#015 30%|███       | 397/1314 [03:11<07:18,  2.09it/s]#015 30%|███       | 398/1314 [03:12<07:20,  2.08it/s]#015 30%|███       | 399/1314 [03:12<07:19,  2.08it/s]#015 30%|███       | 400/1314 [03:13<07:19,  2.08it/s]#015 31%|███       | 401/1314 [03:13<07:19,  2.08it/s]#015 31%|███       | 402/1314 [03:14<07:17,  2.08it/s]#015 31%|███       | 403/1314 [03:14<07:17,  2.08it/s]#015 31%|███       | 404/1314 [03:15<07:17,  2.08it/s]#015 31%|███       | 405/1314 [03:15<07:18,  2.07it/s]#015 31%|███       | 406/1314 [03:16<07:18,  2.07it/s]#015 31%|███       | 407/1314 [03:16<07:16,  2.08it/s]#015 31%|███       | 408/1314 [03:17<07:15,  2.08it/s]#015 31%|███       | 409/1314 [03:17<07:16,  2.07it/s]#015 31%|███       | 410/1314 [03:18<07:18,  2.06it/s]#015 31%|███▏      | 411/1314 [03:18<07:16,  2.07it/s]#015 31%|███▏      | 412/1314 [03:19<07:14,  2.08it/s]#015 31%|███▏      | 413/1314 [03:19<07:12,  2.08it/s]#015 32%|███▏      | 414/1314 [03:20<07:10,  2.09it/s]#015 32%|███▏      | 415/1314 [03:20<07:09,  2.10it/s]#015 32%|███▏      | 416/1314 [03:20<07:09,  2.09it/s]#015 32%|███▏      | 417/1314 [03:21<07:07,  2.10it/s]#015 32%|███▏      | 418/1314 [03:21<07:06,  2.10it/s]#015 32%|███▏      | 419/1314 [03:22<07:06,  2.10it/s]#015 32%|███▏      | 420/1314 [03:22<07:05,  2.10it/s]#015 32%|███▏      | 421/1314 [03:23<07:05,  2.10it/s]#015 32%|███▏      | 422/1314 [03:23<07:05,  2.09it/s]#015 32%|███▏      | 423/1314 [03:24<07:05,  2.10it/s]#015 32%|███▏      | 424/1314 [03:24<07:05,  2.09it/s]#015 32%|███▏      | 425/1314 [03:25<07:05,  2.09it/s]#015 32%|███▏      | 426/1314 [03:25<07:05,  2.09it/s]#015 32%|███▏      | 427/1314 [03:26<07:05,  2.08it/s]#015 33%|███▎      | 428/1314 [03:26<07:05,  2.08it/s]#015 33%|███▎      | 429/1314 [03:27<07:05,  2.08it/s]#015 33%|███▎      | 430/1314 [03:27<07:06,  2.07it/s]#015 33%|███▎      | 431/1314 [03:28<07:05,  2.08it/s]#015 33%|███▎      | 432/1314 [03:28<07:02,  2.09it/s]#015 33%|███▎      | 433/1314 [03:29<07:00,  2.09it/s]#015 33%|███▎      | 434/1314 [03:29<07:01,  2.09it/s]#015 33%|███▎      | 435/1314 [03:30<07:00,  2.09it/s]#015 33%|███▎      | 436/1314 [03:30<07:00,  2.09it/s]#015 33%|███▎      | 437/1314 [03:31<07:00,  2.08it/s]#015 33%|███▎      | 438/1314 [03:31<05:54,  2.47it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 3500\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/55 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|▎         | 2/55 [00:00<00:08,  6.23it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|▌         | 3/55 [00:00<00:11,  4.41it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|▋         | 4/55 [00:00<00:13,  3.82it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|▉         | 5/55 [00:01<00:14,  3.54it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|█         | 6/55 [00:01<00:14,  3.39it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|█▎        | 7/55 [00:01<00:14,  3.29it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|█▍        | 8/55 [00:02<00:14,  3.23it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|█▋        | 9/55 [00:02<00:14,  3.19it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|█▊        | 10/55 [00:02<00:14,  3.17it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|██        | 11/55 [00:03<00:13,  3.15it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|██▏       | 12/55 [00:03<00:13,  3.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|██▎       | 13/55 [00:03<00:13,  3.13it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|██▌       | 14/55 [00:04<00:13,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|██▋       | 15/55 [00:04<00:12,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|██▉       | 16/55 [00:04<00:12,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|███       | 17/55 [00:05<00:12,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|███▎      | 18/55 [00:05<00:11,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|███▍      | 19/55 [00:05<00:11,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|███▋      | 20/55 [00:06<00:11,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|███▊      | 21/55 [00:06<00:10,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|████      | 22/55 [00:06<00:10,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|████▏     | 23/55 [00:07<00:10,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|████▎     | 24/55 [00:07<00:09,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|████▌     | 25/55 [00:07<00:09,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|████▋     | 26/55 [00:08<00:09,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|████▉     | 27/55 [00:08<00:09,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|█████     | 28/55 [00:08<00:08,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|█████▎    | 29/55 [00:09<00:08,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|█████▍    | 30/55 [00:09<00:08,  3.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|█████▋    | 31/55 [00:09<00:07,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|█████▊    | 32/55 [00:09<00:07,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|██████    | 33/55 [00:10<00:07,  3.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|██████▏   | 34/55 [00:10<00:06,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|██████▎   | 35/55 [00:10<00:06,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|██████▌   | 36/55 [00:11<00:06,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|██████▋   | 37/55 [00:11<00:05,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|██████▉   | 38/55 [00:11<00:05,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|███████   | 39/55 [00:12<00:05,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|███████▎  | 40/55 [00:12<00:04,  3.12it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|███████▍  | 41/55 [00:12<00:04,  3.12it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|███████▋  | 42/55 [00:13<00:04,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|███████▊  | 43/55 [00:13<00:03,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|████████  | 44/55 [00:13<00:03,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|████████▏ | 45/55 [00:14<00:03,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|████████▎ | 46/55 [00:14<00:02,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|████████▌ | 47/55 [00:14<00:02,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|████████▋ | 48/55 [00:15<00:02,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|████████▉ | 49/55 [00:15<00:01,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|█████████ | 50/55 [00:15<00:01,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|█████████▎| 51/55 [00:16<00:01,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|█████████▍| 52/55 [00:16<00:00,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|█████████▋| 53/55 [00:16<00:00,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|█████████▊| 54/55 [00:17<00:00,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 55/55 [00:17<00:00,  3.41it/s]#033[A#015                                                  #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015 33%|███▎      | 438/1314 [03:49<05:54,  2.47it/s]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 55/55 [00:17<00:00,  3.41it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A#015 33%|███▎      | 439/1314 [03:49<1:24:01,  5.76s/it]#015 33%|███▎      | 440/1314 [03:49<1:00:49,  4.18s/it]#015 34%|███▎      | 441/1314 [03:50<44:35,  3.07s/it]  #015 34%|███▎      | 442/1314 [03:50<33:14,  2.29s/it]#015 34%|███▎      | 443/1314 [03:51<25:18,  1.74s/it]#015 34%|███▍      | 444/1314 [03:51<19:45,  1.36s/it]#015 34%|███▍      | 445/1314 [03:52<15:55,  1.10s/it]#015 34%|███▍      | 446/1314 [03:52<13:14,  1.09it/s]#015 34%|███▍      | 447/1314 [03:53<11:21,  1.27it/s]#015 34%|███▍      | 448/1314 [03:53<10:00,  1.44it/s]#015 34%|███▍      | 449/1314 [03:54<09:04,  1.59it/s]#015 34%|███▍      | 450/1314 [03:54<08:24,  1.71it/s]#015 34%|███▍      | 451/1314 [03:55<07:56,  1.81it/s]#015 34%|███▍      | 452/1314 [03:55<07:36,  1.89it/s]#015 34%|███▍      | 453/1314 [03:56<07:22,  1.95it/s]#015 35%|███▍      | 454/1314 [03:56<07:11,  1.99it/s]#015 35%|███▍      | 455/1314 [03:57<07:04,  2.03it/s]#015 35%|███▍      | 456/1314 [03:57<06:59,  2.05it/s]#015 35%|███▍      | 457/1314 [03:58<06:56,  2.06it/s]#015 35%|███▍      | 458/1314 [03:58<06:53,  2.07it/s]#015 35%|███▍      | 459/1314 [03:59<06:50,  2.08it/s]#015 35%|███▌      | 460/1314 [03:59<06:50,  2.08it/s]#015 35%|███▌      | 461/1314 [04:00<06:48,  2.09it/s]#015 35%|███▌      | 462/1314 [04:00<06:47,  2.09it/s]#015 35%|███▌      | 463/1314 [04:00<06:46,  2.09it/s]#015 35%|███▌      | 464/1314 [04:01<06:45,  2.10it/s]#015 35%|███▌      | 465/1314 [04:01<06:45,  2.10it/s]#015 35%|███▌      | 466/1314 [04:02<06:44,  2.09it/s]#015 36%|███▌      | 467/1314 [04:02<06:44,  2.10it/s]#015 36%|███▌      | 468/1314 [04:03<06:43,  2.10it/s]#015 36%|███▌      | 469/1314 [04:03<06:42,  2.10it/s]#015 36%|███▌      | 470/1314 [04:04<06:41,  2.10it/s]#015 36%|███▌      | 471/1314 [04:04<06:41,  2.10it/s]#015 36%|███▌      | 472/1314 [04:05<06:42,  2.09it/s]#015 36%|███▌      | 473/1314 [04:05<06:41,  2.10it/s]#015 36%|███▌      | 474/1314 [04:06<06:40,  2.10it/s]#015 36%|███▌      | 475/1314 [04:06<06:39,  2.10it/s]#015 36%|███▌      | 476/1314 [04:07<06:38,  2.10it/s]#015 36%|███▋      | 477/1314 [04:07<06:39,  2.09it/s]#015 36%|███▋      | 478/1314 [04:08<06:40,  2.09it/s]#015 36%|███▋      | 479/1314 [04:08<06:38,  2.09it/s]#015 37%|███▋      | 480/1314 [04:09<06:37,  2.10it/s]#015 37%|███▋      | 481/1314 [04:09<06:37,  2.10it/s]#015 37%|███▋      | 482/1314 [04:10<06:37,  2.10it/s]#015 37%|███▋      | 483/1314 [04:10<06:37,  2.09it/s]#015 37%|███▋      | 484/1314 [04:10<06:37,  2.09it/s]#015 37%|███▋      | 485/1314 [04:11<06:36,  2.09it/s]#015 37%|███▋      | 486/1314 [04:11<06:36,  2.09it/s]#015 37%|███▋      | 487/1314 [04:12<06:35,  2.09it/s]#015 37%|███▋      | 488/1314 [04:12<06:34,  2.10it/s]#015 37%|███▋      | 489/1314 [04:13<06:34,  2.09it/s]#015 37%|███▋      | 490/1314 [04:13<06:35,  2.09it/s]#015 37%|███▋      | 491/1314 [04:14<06:36,  2.07it/s]#015 37%|███▋      | 492/1314 [04:14<06:38,  2.06it/s]#015 38%|███▊      | 493/1314 [04:15<06:36,  2.07it/s]#015 38%|███▊      | 494/1314 [04:15<06:36,  2.07it/s]#015 38%|███▊      | 495/1314 [04:16<06:37,  2.06it/s]#015 38%|███▊      | 496/1314 [04:16<06:35,  2.07it/s]#015 38%|███▊      | 497/1314 [04:17<06:35,  2.06it/s]#015 38%|███▊      | 498/1314 [04:17<06:36,  2.06it/s]#015 38%|███▊      | 499/1314 [04:18<06:37,  2.05it/s]#015 38%|███▊      | 500/1314 [04:18<06:34,  2.06it/s]#015                                                  #015#015 38%|███▊      | 500/1314 [04:18<06:34,  2.06it/s]Saving model checkpoint to /opt/ml/model/checkpoint-500\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-500/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-500/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-500/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-500/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m#015 38%|███▊      | 501/1314 [04:20<12:35,  1.08it/s]#015 38%|███▊      | 502/1314 [04:21<10:44,  1.26it/s]#015 38%|███▊      | 503/1314 [04:21<09:26,  1.43it/s]#015 38%|███▊      | 504/1314 [04:22<08:31,  1.58it/s]#015 38%|███▊      | 505/1314 [04:22<07:53,  1.71it/s]#015 39%|███▊      | 506/1314 [04:23<07:26,  1.81it/s]#015 39%|███▊      | 507/1314 [04:23<07:07,  1.89it/s]#015 39%|███▊      | 508/1314 [04:24<06:54,  1.95it/s]#015 39%|███▊      | 509/1314 [04:24<06:44,  1.99it/s]#015 39%|███▉      | 510/1314 [04:24<06:38,  2.02it/s]#015 39%|███▉      | 511/1314 [04:25<06:33,  2.04it/s]#015 39%|███▉      | 512/1314 [04:25<06:30,  2.06it/s]#015 39%|███▉      | 513/1314 [04:26<06:28,  2.06it/s]#015 39%|███▉      | 514/1314 [04:26<06:25,  2.07it/s]#015 39%|███▉      | 515/1314 [04:27<06:23,  2.08it/s]#015 39%|███▉      | 516/1314 [04:27<06:22,  2.09it/s]#015 39%|███▉      | 517/1314 [04:28<06:22,  2.09it/s]#015 39%|███▉      | 518/1314 [04:28<06:22,  2.08it/s]#015 39%|███▉      | 519/1314 [04:29<06:21,  2.08it/s]#015 40%|███▉      | 520/1314 [04:29<06:20,  2.08it/s]#015 40%|███▉      | 521/1314 [04:30<06:19,  2.09it/s]#015 40%|███▉      | 522/1314 [04:30<06:18,  2.09it/s]#015 40%|███▉      | 523/1314 [04:31<06:18,  2.09it/s]#015 40%|███▉      | 524/1314 [04:31<06:17,  2.09it/s]#015 40%|███▉      | 525/1314 [04:32<06:16,  2.10it/s]#015 40%|████      | 526/1314 [04:32<06:14,  2.10it/s]#015 40%|████      | 527/1314 [04:33<06:14,  2.10it/s]#015 40%|████      | 528/1314 [04:33<06:13,  2.10it/s]#015 40%|████      | 529/1314 [04:34<06:14,  2.10it/s]#015 40%|████      | 530/1314 [04:34<06:13,  2.10it/s]#015 40%|████      | 531/1314 [04:34<06:13,  2.10it/s]#015 40%|████      | 532/1314 [04:35<06:13,  2.09it/s]#015 41%|████      | 533/1314 [04:35<06:13,  2.09it/s]#015 41%|████      | 534/1314 [04:36<06:12,  2.09it/s]#015 41%|████      | 535/1314 [04:36<06:12,  2.09it/s]#015 41%|████      | 536/1314 [04:37<06:10,  2.10it/s]#015 41%|████      | 537/1314 [04:37<06:10,  2.10it/s]#015 41%|████      | 538/1314 [04:38<06:09,  2.10it/s]#015 41%|████      | 539/1314 [04:38<06:08,  2.10it/s]#015 41%|████      | 540/1314 [04:39<06:07,  2.10it/s]#015 41%|████      | 541/1314 [04:39<06:08,  2.10it/s]#015 41%|████      | 542/1314 [04:40<06:09,  2.09it/s]#015 41%|████▏     | 543/1314 [04:40<06:08,  2.09it/s]#015 41%|████▏     | 544/1314 [04:41<06:09,  2.08it/s]#015 41%|████▏     | 545/1314 [04:41<06:09,  2.08it/s]#015 42%|████▏     | 546/1314 [04:42<06:08,  2.09it/s]#015 42%|████▏     | 547/1314 [04:42<06:07,  2.09it/s]#015 42%|████▏     | 548/1314 [04:43<06:07,  2.09it/s]#015 42%|████▏     | 549/1314 [04:43<06:06,  2.08it/s]#015 42%|████▏     | 550/1314 [04:44<06:08,  2.08it/s]#015 42%|████▏     | 551/1314 [04:44<06:07,  2.08it/s]#015 42%|████▏     | 552/1314 [04:45<06:06,  2.08it/s]#015 42%|████▏     | 553/1314 [04:45<06:05,  2.08it/s]#015 42%|████▏     | 554/1314 [04:46<06:04,  2.08it/s]#015 42%|████▏     | 555/1314 [04:46<06:04,  2.08it/s]#015 42%|████▏     | 556/1314 [04:46<06:03,  2.09it/s]#015 42%|████▏     | 557/1314 [04:47<06:02,  2.09it/s]#015 42%|████▏     | 558/1314 [04:47<06:01,  2.09it/s]#015 43%|████▎     | 559/1314 [04:48<06:00,  2.10it/s]#015 43%|████▎     | 560/1314 [04:48<06:00,  2.09it/s]#015 43%|████▎     | 561/1314 [04:49<06:00,  2.09it/s]#015 43%|████▎     | 562/1314 [04:49<05:59,  2.09it/s]#015 43%|████▎     | 563/1314 [04:50<05:57,  2.10it/s]#015 43%|████▎     | 564/1314 [04:50<05:57,  2.10it/s]#015 43%|████▎     | 565/1314 [04:51<05:56,  2.10it/s]#015 43%|████▎     | 566/1314 [04:51<05:55,  2.10it/s]#015 43%|████▎     | 567/1314 [04:52<05:55,  2.10it/s]#015 43%|████▎     | 568/1314 [04:52<05:55,  2.10it/s]#015 43%|████▎     | 569/1314 [04:53<05:54,  2.10it/s]#015 43%|████▎     | 570/1314 [04:53<05:53,  2.10it/s]#015 43%|████▎     | 571/1314 [04:54<05:53,  2.10it/s]#015 44%|████▎     | 572/1314 [04:54<05:53,  2.10it/s]#015 44%|████▎     | 573/1314 [04:55<05:53,  2.10it/s]#015 44%|████▎     | 574/1314 [04:55<05:54,  2.09it/s]#015 44%|████▍     | 575/1314 [04:56<05:53,  2.09it/s]#015 44%|████▍     | 576/1314 [04:56<05:52,  2.10it/s]#015 44%|████▍     | 577/1314 [04:56<05:51,  2.10it/s]#015 44%|████▍     | 578/1314 [04:57<05:51,  2.10it/s]#015 44%|████▍     | 579/1314 [04:57<05:51,  2.09it/s]#015 44%|████▍     | 580/1314 [04:58<05:50,  2.10it/s]#015 44%|████▍     | 581/1314 [04:58<05:49,  2.10it/s]#015 44%|████▍     | 582/1314 [04:59<05:49,  2.09it/s]#015 44%|████▍     | 583/1314 [04:59<05:48,  2.10it/s]#015 44%|████▍     | 584/1314 [05:00<05:48,  2.10it/s]#015 45%|████▍     | 585/1314 [05:00<05:47,  2.10it/s]#015 45%|████▍     | 586/1314 [05:01<05:46,  2.10it/s]#015 45%|████▍     | 587/1314 [05:01<05:46,  2.10it/s]#015 45%|████▍     | 588/1314 [05:02<05:45,  2.10it/s]#015 45%|████▍     | 589/1314 [05:02<05:45,  2.10it/s]#015 45%|████▍     | 590/1314 [05:03<05:44,  2.10it/s]#015 45%|████▍     | 591/1314 [05:03<05:44,  2.10it/s]#015 45%|████▌     | 592/1314 [05:04<05:44,  2.10it/s]#015 45%|████▌     | 593/1314 [05:04<05:44,  2.09it/s]#015 45%|████▌     | 594/1314 [05:05<05:44,  2.09it/s]#015 45%|████▌     | 595/1314 [05:05<05:43,  2.09it/s]#015 45%|████▌     | 596/1314 [05:06<05:43,  2.09it/s]#015 45%|████▌     | 597/1314 [05:06<05:42,  2.09it/s]#015 46%|████▌     | 598/1314 [05:07<05:41,  2.09it/s]#015 46%|████▌     | 599/1314 [05:07<05:43,  2.08it/s]#015 46%|████▌     | 600/1314 [05:07<05:42,  2.08it/s]#015 46%|████▌     | 601/1314 [05:08<05:42,  2.08it/s]#015 46%|████▌     | 602/1314 [05:08<05:42,  2.08it/s]#015 46%|████▌     | 603/1314 [05:09<05:40,  2.09it/s]#015 46%|████▌     | 604/1314 [05:09<05:40,  2.08it/s]#015 46%|████▌     | 605/1314 [05:10<05:40,  2.08it/s]#015 46%|████▌     | 606/1314 [05:10<05:39,  2.09it/s]#015 46%|████▌     | 607/1314 [05:11<05:37,  2.09it/s]#015 46%|████▋     | 608/1314 [05:11<05:37,  2.09it/s]#015 46%|████▋     | 609/1314 [05:12<05:37,  2.09it/s]#015 46%|████▋     | 610/1314 [05:12<05:38,  2.08it/s]#015 46%|████▋     | 611/1314 [05:13<05:36,  2.09it/s]#015 47%|████▋     | 612/1314 [05:13<05:35,  2.09it/s]#015 47%|████▋     | 613/1314 [05:14<05:36,  2.08it/s]#015 47%|████▋     | 614/1314 [05:14<05:40,  2.06it/s]#015 47%|████▋     | 615/1314 [05:15<05:37,  2.07it/s]#015 47%|████▋     | 616/1314 [05:15<05:36,  2.08it/s]#015 47%|████▋     | 617/1314 [05:16<05:34,  2.08it/s]#015 47%|████▋     | 618/1314 [05:16<05:33,  2.08it/s]#015 47%|████▋     | 619/1314 [05:17<05:32,  2.09it/s]#015 47%|████▋     | 620/1314 [05:17<05:32,  2.09it/s]#015 47%|████▋     | 621/1314 [05:18<05:32,  2.08it/s]#015 47%|████▋     | 622/1314 [05:18<05:33,  2.08it/s]#015 47%|████▋     | 623/1314 [05:19<05:32,  2.08it/s]#015 47%|████▋     | 624/1314 [05:19<05:30,  2.08it/s]#015 48%|████▊     | 625/1314 [05:19<05:29,  2.09it/s]#015 48%|████▊     | 626/1314 [05:20<05:28,  2.09it/s]#015 48%|████▊     | 627/1314 [05:20<05:27,  2.10it/s]#015 48%|████▊     | 628/1314 [05:21<05:27,  2.10it/s]#015 48%|████▊     | 629/1314 [05:21<05:26,  2.10it/s]#015 48%|████▊     | 630/1314 [05:22<05:26,  2.10it/s]#015 48%|████▊     | 631/1314 [05:22<05:27,  2.09it/s]#015 48%|████▊     | 632/1314 [05:23<05:26,  2.09it/s]#015 48%|████▊     | 633/1314 [05:23<05:26,  2.09it/s]#015 48%|████▊     | 634/1314 [05:24<05:25,  2.09it/s]#015 48%|████▊     | 635/1314 [05:24<05:25,  2.09it/s]#015 48%|████▊     | 636/1314 [05:25<05:24,  2.09it/s]#015 48%|████▊     | 637/1314 [05:25<05:24,  2.09it/s]#015 49%|████▊     | 638/1314 [05:26<05:22,  2.09it/s]#015 49%|████▊     | 639/1314 [05:26<05:23,  2.09it/s]#015 49%|████▊     | 640/1314 [05:27<05:23,  2.09it/s]#015 49%|████▉     | 641/1314 [05:27<05:23,  2.08it/s]#015 49%|████▉     | 642/1314 [05:28<05:23,  2.08it/s]#015 49%|████▉     | 643/1314 [05:28<05:22,  2.08it/s]#015 49%|████▉     | 644/1314 [05:29<05:22,  2.08it/s]#015 49%|████▉     | 645/1314 [05:29<05:21,  2.08it/s]#015 49%|████▉     | 646/1314 [05:30<05:20,  2.08it/s]#015 49%|████▉     | 647/1314 [05:30<05:21,  2.07it/s]#015 49%|████▉     | 648/1314 [05:30<05:20,  2.08it/s]#015 49%|████▉     | 649/1314 [05:31<05:19,  2.08it/s]#015 49%|████▉     | 650/1314 [05:31<05:17,  2.09it/s]#015 50%|████▉     | 651/1314 [05:32<05:17,  2.09it/s]#015 50%|████▉     | 652/1314 [05:32<05:16,  2.09it/s]#015 50%|████▉     | 653/1314 [05:33<05:15,  2.09it/s]#015 50%|████▉     | 654/1314 [05:33<05:14,  2.10it/s]#015 50%|████▉     | 655/1314 [05:34<05:14,  2.09it/s]#015 50%|████▉     | 656/1314 [05:34<05:15,  2.08it/s]#015 50%|█████     | 657/1314 [05:35<05:14,  2.09it/s]#015 50%|█████     | 658/1314 [05:35<05:13,  2.09it/s]#015 50%|█████     | 659/1314 [05:36<05:12,  2.09it/s]#015 50%|█████     | 660/1314 [05:36<05:11,  2.10it/s]#015 50%|█████     | 661/1314 [05:37<05:11,  2.10it/s]#015 50%|█████     | 662/1314 [05:37<05:10,  2.10it/s]#015 50%|█████     | 663/1314 [05:38<05:10,  2.10it/s]#015 51%|█████     | 664/1314 [05:38<05:10,  2.09it/s]#015 51%|█████     | 665/1314 [05:39<05:09,  2.10it/s]#015 51%|█████     | 666/1314 [05:39<05:08,  2.10it/s]#015 51%|█████     | 667/1314 [05:40<05:07,  2.10it/s]#015 51%|█████     | 668/1314 [05:40<05:07,  2.10it/s]#015 51%|█████     | 669/1314 [05:41<05:07,  2.10it/s]#015 51%|█████     | 670/1314 [05:41<05:06,  2.10it/s]#015 51%|█████     | 671/1314 [05:41<05:06,  2.10it/s]#015 51%|█████     | 672/1314 [05:42<05:05,  2.10it/s]#015 51%|█████     | 673/1314 [05:42<05:04,  2.10it/s]#015 51%|█████▏    | 674/1314 [05:43<05:04,  2.10it/s]#015 51%|█████▏    | 675/1314 [05:43<05:04,  2.10it/s]#015 51%|█████▏    | 676/1314 [05:44<05:04,  2.09it/s]#015 52%|█████▏    | 677/1314 [05:44<05:04,  2.09it/s]#015 52%|█████▏    | 678/1314 [05:45<05:03,  2.10it/s]#015 52%|█████▏    | 679/1314 [05:45<05:02,  2.10it/s]#015 52%|█████▏    | 680/1314 [05:46<05:02,  2.09it/s]#015 52%|█████▏    | 681/1314 [05:46<05:02,  2.09it/s]#015 52%|█████▏    | 682/1314 [05:47<05:02,  2.09it/s]#015 52%|█████▏    | 683/1314 [05:47<05:03,  2.08it/s]#015 52%|█████▏    | 684/1314 [05:48<05:02,  2.08it/s]#015 52%|█████▏    | 685/1314 [05:48<05:01,  2.09it/s]#015 52%|█████▏    | 686/1314 [05:49<05:02,  2.08it/s]#015 52%|█████▏    | 687/1314 [05:49<05:00,  2.08it/s]#015 52%|█████▏    | 688/1314 [05:50<04:59,  2.09it/s]#015 52%|█████▏    | 689/1314 [05:50<04:59,  2.09it/s]#015 53%|█████▎    | 690/1314 [05:51<04:58,  2.09it/s]#015 53%|█████▎    | 691/1314 [05:51<04:58,  2.09it/s]#015 53%|█████▎    | 692/1314 [05:52<04:57,  2.09it/s]#015 53%|█████▎    | 693/1314 [05:52<04:56,  2.10it/s]#015 53%|█████▎    | 694/1314 [05:52<04:55,  2.10it/s]#015 53%|█████▎    | 695/1314 [05:53<04:54,  2.10it/s]#015 53%|█████▎    | 696/1314 [05:53<04:53,  2.10it/s]#015 53%|█████▎    | 697/1314 [05:54<04:54,  2.10it/s]#015 53%|█████▎    | 698/1314 [05:54<04:54,  2.10it/s]#015 53%|█████▎    | 699/1314 [05:55<04:53,  2.10it/s]#015 53%|█████▎    | 700/1314 [05:55<04:53,  2.09it/s]#015 53%|█████▎    | 701/1314 [05:56<04:52,  2.09it/s]#015 53%|█████▎    | 702/1314 [05:56<04:54,  2.08it/s]#015 54%|█████▎    | 703/1314 [05:57<04:53,  2.08it/s]#015 54%|█████▎    | 704/1314 [05:57<04:52,  2.09it/s]#015 54%|█████▎    | 705/1314 [05:58<04:51,  2.09it/s]#015 54%|█████▎    | 706/1314 [05:58<04:51,  2.08it/s]#015 54%|█████▍    | 707/1314 [05:59<04:51,  2.08it/s]#015 54%|█████▍    | 708/1314 [05:59<04:50,  2.09it/s]#015 54%|█████▍    | 709/1314 [06:00<04:49,  2.09it/s]#015 54%|█████▍    | 710/1314 [06:00<04:50,  2.08it/s]#015 54%|█████▍    | 711/1314 [06:01<04:49,  2.08it/s]#015 54%|█████▍    | 712/1314 [06:01<04:48,  2.09it/s]#015 54%|█████▍    | 713/1314 [06:02<04:48,  2.09it/s]#015 54%|█████▍    | 714/1314 [06:02<04:48,  2.08it/s]#015 54%|█████▍    | 715/1314 [06:03<04:47,  2.08it/s]#015 54%|█████▍    | 716/1314 [06:03<04:46,  2.09it/s]#015 55%|█████▍    | 717/1314 [06:03<04:45,  2.09it/s]#015 55%|█████▍    | 718/1314 [06:04<04:44,  2.10it/s]#015 55%|█████▍    | 719/1314 [06:04<04:43,  2.10it/s]#015 55%|█████▍    | 720/1314 [06:05<04:43,  2.10it/s]#015 55%|█████▍    | 721/1314 [06:05<04:42,  2.10it/s]#015 55%|█████▍    | 722/1314 [06:06<04:42,  2.09it/s]#015 55%|█████▌    | 723/1314 [06:06<04:41,  2.10it/s]#015 55%|█████▌    | 724/1314 [06:07<04:40,  2.10it/s]#015 55%|█████▌    | 725/1314 [06:07<04:40,  2.10it/s]#015 55%|█████▌    | 726/1314 [06:08<04:40,  2.10it/s]#015 55%|█████▌    | 727/1314 [06:08<04:40,  2.10it/s]#015 55%|█████▌    | 728/1314 [06:09<04:39,  2.10it/s]#015 55%|█████▌    | 729/1314 [06:09<04:38,  2.10it/s]#015 56%|█████▌    | 730/1314 [06:10<04:37,  2.10it/s]#015 56%|█████▌    | 731/1314 [06:10<04:36,  2.10it/s]#015 56%|█████▌    | 732/1314 [06:11<04:36,  2.10it/s]#015 56%|█████▌    | 733/1314 [06:11<04:36,  2.10it/s]#015 56%|█████▌    | 734/1314 [06:12<04:35,  2.10it/s]#015 56%|█████▌    | 735/1314 [06:12<04:35,  2.10it/s]#015 56%|█████▌    | 736/1314 [06:13<04:35,  2.10it/s]#015 56%|█████▌    | 737/1314 [06:13<04:35,  2.09it/s]#015 56%|█████▌    | 738/1314 [06:13<04:35,  2.09it/s]#015 56%|█████▌    | 739/1314 [06:14<04:35,  2.09it/s]#015 56%|█████▋    | 740/1314 [06:14<04:35,  2.09it/s]#015 56%|█████▋    | 741/1314 [06:15<04:33,  2.09it/s]#015 56%|█████▋    | 742/1314 [06:15<04:33,  2.09it/s]#015 57%|█████▋    | 743/1314 [06:16<04:34,  2.08it/s]#015 57%|█████▋    | 744/1314 [06:16<04:34,  2.08it/s]#015 57%|█████▋    | 745/1314 [06:17<04:34,  2.07it/s]#015 57%|█████▋    | 746/1314 [06:17<04:34,  2.07it/s]#015 57%|█████▋    | 747/1314 [06:18<04:33,  2.07it/s]#015 57%|█████▋    | 748/1314 [06:18<04:32,  2.08it/s]#015 57%|█████▋    | 749/1314 [06:19<04:31,  2.08it/s]#015 57%|█████▋    | 750/1314 [06:19<04:30,  2.08it/s]#015 57%|█████▋    | 751/1314 [06:20<04:29,  2.09it/s]#015 57%|█████▋    | 752/1314 [06:20<04:28,  2.09it/s]#015 57%|█████▋    | 753/1314 [06:21<04:27,  2.10it/s]#015 57%|█████▋    | 754/1314 [06:21<04:26,  2.10it/s]#015 57%|█████▋    | 755/1314 [06:22<04:26,  2.10it/s]#015 58%|█████▊    | 756/1314 [06:22<04:26,  2.10it/s]#015 58%|█████▊    | 757/1314 [06:23<04:25,  2.10it/s]#015 58%|█████▊    | 758/1314 [06:23<04:25,  2.09it/s]#015 58%|█████▊    | 759/1314 [06:24<04:26,  2.09it/s]#015 58%|█████▊    | 760/1314 [06:24<04:25,  2.09it/s]#015 58%|█████▊    | 761/1314 [06:24<04:24,  2.09it/s]#015 58%|█████▊    | 762/1314 [06:25<04:23,  2.09it/s]#015 58%|█████▊    | 763/1314 [06:25<04:24,  2.09it/s]#015 58%|█████▊    | 764/1314 [06:26<04:23,  2.08it/s]#015 58%|█████▊    | 765/1314 [06:26<04:23,  2.08it/s]#015 58%|█████▊    | 766/1314 [06:27<04:23,  2.08it/s]#015 58%|█████▊    | 767/1314 [06:27<04:22,  2.\u001b[0m\n",
      "\u001b[34m09it/s]#015 58%|█████▊    | 768/1314 [06:28<04:21,  2.09it/s]#015 59%|█████▊    | 769/1314 [06:28<04:21,  2.08it/s]#015 59%|█████▊    | 770/1314 [06:29<04:21,  2.08it/s]#015 59%|█████▊    | 771/1314 [06:29<04:21,  2.08it/s]#015 59%|█████▉    | 772/1314 [06:30<04:20,  2.08it/s]#015 59%|█████▉    | 773/1314 [06:30<04:19,  2.08it/s]#015 59%|█████▉    | 774/1314 [06:31<04:19,  2.08it/s]#015 59%|█████▉    | 775/1314 [06:31<04:17,  2.09it/s]#015 59%|█████▉    | 776/1314 [06:32<04:17,  2.09it/s]#015 59%|█████▉    | 777/1314 [06:32<04:17,  2.09it/s]#015 59%|█████▉    | 778/1314 [06:33<04:17,  2.08it/s]#015 59%|█████▉    | 779/1314 [06:33<04:16,  2.08it/s]#015 59%|█████▉    | 780/1314 [06:34<04:16,  2.08it/s]#015 59%|█████▉    | 781/1314 [06:34<04:16,  2.08it/s]#015 60%|█████▉    | 782/1314 [06:35<04:16,  2.07it/s]#015 60%|█████▉    | 783/1314 [06:35<04:15,  2.08it/s]#015 60%|█████▉    | 784/1314 [06:36<04:14,  2.08it/s]#015 60%|█████▉    | 785/1314 [06:36<04:12,  2.09it/s]#015 60%|█████▉    | 786/1314 [06:36<04:12,  2.09it/s]#015 60%|█████▉    | 787/1314 [06:37<04:11,  2.09it/s]#015 60%|█████▉    | 788/1314 [06:37<04:11,  2.09it/s]#015 60%|██████    | 789/1314 [06:38<04:10,  2.09it/s]#015 60%|██████    | 790/1314 [06:38<04:10,  2.09it/s]#015 60%|██████    | 791/1314 [06:39<04:11,  2.08it/s]#015 60%|██████    | 792/1314 [06:39<04:09,  2.09it/s]#015 60%|██████    | 793/1314 [06:40<04:09,  2.09it/s]#015 60%|██████    | 794/1314 [06:40<04:08,  2.09it/s]#015 61%|██████    | 795/1314 [06:41<04:07,  2.10it/s]#015 61%|██████    | 796/1314 [06:41<04:07,  2.09it/s]#015 61%|██████    | 797/1314 [06:42<04:06,  2.09it/s]#015 61%|██████    | 798/1314 [06:42<04:06,  2.09it/s]#015 61%|██████    | 799/1314 [06:43<04:05,  2.10it/s]#015 61%|██████    | 800/1314 [06:43<04:05,  2.10it/s]#015 61%|██████    | 801/1314 [06:44<04:04,  2.10it/s]#015 61%|██████    | 802/1314 [06:44<04:04,  2.09it/s]#015 61%|██████    | 803/1314 [06:45<04:03,  2.10it/s]#015 61%|██████    | 804/1314 [06:45<04:02,  2.10it/s]#015 61%|██████▏   | 805/1314 [06:46<04:02,  2.10it/s]#015 61%|██████▏   | 806/1314 [06:46<04:01,  2.10it/s]#015 61%|██████▏   | 807/1314 [06:47<04:01,  2.10it/s]#015 61%|██████▏   | 808/1314 [06:47<04:01,  2.10it/s]#015 62%|██████▏   | 809/1314 [06:47<04:00,  2.10it/s]#015 62%|██████▏   | 810/1314 [06:48<04:00,  2.09it/s]#015 62%|██████▏   | 811/1314 [06:48<03:59,  2.10it/s]#015 62%|██████▏   | 812/1314 [06:49<03:59,  2.10it/s]#015 62%|██████▏   | 813/1314 [06:49<03:59,  2.09it/s]#015 62%|██████▏   | 814/1314 [06:50<04:00,  2.08it/s]#015 62%|██████▏   | 815/1314 [06:50<03:59,  2.09it/s]#015 62%|██████▏   | 816/1314 [06:51<03:58,  2.09it/s]#015 62%|██████▏   | 817/1314 [06:51<03:58,  2.09it/s]#015 62%|██████▏   | 818/1314 [06:52<03:57,  2.09it/s]#015 62%|██████▏   | 819/1314 [06:52<03:57,  2.09it/s]#015 62%|██████▏   | 820/1314 [06:53<03:56,  2.09it/s]#015 62%|██████▏   | 821/1314 [06:53<03:55,  2.09it/s]#015 63%|██████▎   | 822/1314 [06:54<03:55,  2.09it/s]#015 63%|██████▎   | 823/1314 [06:54<03:55,  2.09it/s]#015 63%|██████▎   | 824/1314 [06:55<03:54,  2.09it/s]#015 63%|██████▎   | 825/1314 [06:55<03:54,  2.09it/s]#015 63%|██████▎   | 826/1314 [06:56<03:54,  2.08it/s]#015 63%|██████▎   | 827/1314 [06:56<03:53,  2.08it/s]#015 63%|██████▎   | 828/1314 [06:57<03:52,  2.09it/s]#015 63%|██████▎   | 829/1314 [06:57<03:51,  2.09it/s]#015 63%|██████▎   | 830/1314 [06:58<03:52,  2.09it/s]#015 63%|██████▎   | 831/1314 [06:58<03:51,  2.08it/s]#015 63%|██████▎   | 832/1314 [06:58<03:50,  2.09it/s]#015 63%|██████▎   | 833/1314 [06:59<03:50,  2.09it/s]#015 63%|██████▎   | 834/1314 [06:59<03:49,  2.09it/s]#015 64%|██████▎   | 835/1314 [07:00<03:49,  2.08it/s]#015 64%|██████▎   | 836/1314 [07:00<03:49,  2.08it/s]#015 64%|██████▎   | 837/1314 [07:01<03:48,  2.09it/s]#015 64%|██████▍   | 838/1314 [07:01<03:48,  2.08it/s]#015 64%|██████▍   | 839/1314 [07:02<03:47,  2.09it/s]#015 64%|██████▍   | 840/1314 [07:02<03:47,  2.09it/s]#015 64%|██████▍   | 841/1314 [07:03<03:46,  2.09it/s]#015 64%|██████▍   | 842/1314 [07:03<03:46,  2.09it/s]#015 64%|██████▍   | 843/1314 [07:04<03:45,  2.09it/s]#015 64%|██████▍   | 844/1314 [07:04<03:45,  2.09it/s]#015 64%|██████▍   | 845/1314 [07:05<03:44,  2.09it/s]#015 64%|██████▍   | 846/1314 [07:05<03:44,  2.09it/s]#015 64%|██████▍   | 847/1314 [07:06<03:43,  2.09it/s]#015 65%|██████▍   | 848/1314 [07:06<03:42,  2.10it/s]#015 65%|██████▍   | 849/1314 [07:07<03:41,  2.10it/s]#015 65%|██████▍   | 850/1314 [07:07<03:41,  2.10it/s]#015 65%|██████▍   | 851/1314 [07:08<03:40,  2.10it/s]#015 65%|██████▍   | 852/1314 [07:08<03:40,  2.10it/s]#015 65%|██████▍   | 853/1314 [07:09<03:39,  2.10it/s]#015 65%|██████▍   | 854/1314 [07:09<03:39,  2.09it/s]#015 65%|██████▌   | 855/1314 [07:09<03:39,  2.09it/s]#015 65%|██████▌   | 856/1314 [07:10<03:38,  2.09it/s]#015 65%|██████▌   | 857/1314 [07:10<03:38,  2.09it/s]#015 65%|██████▌   | 858/1314 [07:11<03:38,  2.09it/s]#015 65%|██████▌   | 859/1314 [07:11<03:37,  2.09it/s]#015 65%|██████▌   | 860/1314 [07:12<03:37,  2.09it/s]#015 66%|██████▌   | 861/1314 [07:12<03:36,  2.09it/s]#015 66%|██████▌   | 862/1314 [07:13<03:36,  2.09it/s]#015 66%|██████▌   | 863/1314 [07:13<03:36,  2.09it/s]#015 66%|██████▌   | 864/1314 [07:14<03:35,  2.09it/s]#015 66%|██████▌   | 865/1314 [07:14<03:34,  2.09it/s]#015 66%|██████▌   | 866/1314 [07:15<03:33,  2.10it/s]#015 66%|██████▌   | 867/1314 [07:15<03:33,  2.10it/s]#015 66%|██████▌   | 868/1314 [07:16<03:32,  2.10it/s]#015 66%|██████▌   | 869/1314 [07:16<03:32,  2.10it/s]#015 66%|██████▌   | 870/1314 [07:17<03:31,  2.10it/s]#015 66%|██████▋   | 871/1314 [07:17<03:31,  2.10it/s]#015 66%|██████▋   | 872/1314 [07:18<03:30,  2.10it/s]#015 66%|██████▋   | 873/1314 [07:18<03:30,  2.10it/s]#015 67%|██████▋   | 874/1314 [07:19<03:29,  2.10it/s]#015 67%|██████▋   | 875/1314 [07:19<03:28,  2.10it/s]#015 67%|██████▋   | 876/1314 [07:19<02:55,  2.49it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 3500\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/55 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|▎         | 2/55 [00:00<00:08,  6.22it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|▌         | 3/55 [00:00<00:11,  4.40it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|▋         | 4/55 [00:00<00:13,  3.76it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|▉         | 5/55 [00:01<00:14,  3.50it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|█         | 6/55 [00:01<00:14,  3.37it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|█▎        | 7/55 [00:01<00:14,  3.28it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|█▍        | 8/55 [00:02<00:14,  3.22it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|█▋        | 9/55 [00:02<00:14,  3.19it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|█▊        | 10/55 [00:02<00:14,  3.16it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|██        | 11/55 [00:03<00:13,  3.15it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|██▏       | 12/55 [00:03<00:13,  3.14it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|██▎       | 13/55 [00:03<00:13,  3.13it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|██▌       | 14/55 [00:04<00:13,  3.13it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|██▋       | 15/55 [00:04<00:12,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|██▉       | 16/55 [00:04<00:12,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|███       | 17/55 [00:05<00:12,  3.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|███▎      | 18/55 [00:05<00:11,  3.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|███▍      | 19/55 [00:05<00:11,  3.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|███▋      | 20/55 [00:06<00:11,  3.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|███▊      | 21/55 [00:06<00:11,  3.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|████      | 22/55 [00:06<00:10,  3.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|████▏     | 23/55 [00:07<00:10,  3.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|████▎     | 24/55 [00:07<00:10,  3.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|████▌     | 25/55 [00:07<00:09,  3.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|████▋     | 26/55 [00:08<00:09,  3.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|████▉     | 27/55 [00:08<00:09,  3.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|█████     | 28/55 [00:08<00:08,  3.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|█████▎    | 29/55 [00:09<00:08,  3.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|█████▍    | 30/55 [00:09<00:08,  3.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|█████▋    | 31/55 [00:09<00:07,  3.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|█████▊    | 32/55 [00:10<00:07,  3.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|██████    | 33/55 [00:10<00:07,  3.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|██████▏   | 34/55 [00:10<00:06,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|██████▎   | 35/55 [00:10<00:06,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|██████▌   | 36/55 [00:11<00:06,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|██████▋   | 37/55 [00:11<00:05,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|██████▉   | 38/55 [00:11<00:05,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|███████   | 39/55 [00:12<00:05,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|███████▎  | 40/55 [00:12<00:04,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|███████▍  | 41/55 [00:12<00:04,  3.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|███████▋  | 42/55 [00:13<00:04,  3.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|███████▊  | 43/55 [00:13<00:03,  3.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|████████  | 44/55 [00:13<00:03,  3.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|████████▏ | 45/55 [00:14<00:03,  3.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|████████▎ | 46/55 [00:14<00:02,  3.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|████████▌ | 47/55 [00:14<00:02,  3.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|████████▋ | 48/55 [00:15<00:02,  3.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|████████▉ | 49/55 [00:15<00:01,  3.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|█████████ | 50/55 [00:15<00:01,  3.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|█████████▎| 51/55 [00:16<00:01,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|█████████▍| 52/55 [00:16<00:00,  3.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|█████████▋| 53/55 [00:16<00:00,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|█████████▊| 54/55 [00:17<00:00,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 55/55 [00:17<00:00,  3.38it/s]#033[A#015                                                  #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015 67%|██████▋   | 876/1314 [07:37<02:55,  2.49it/s]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 55/55 [00:17<00:00,  3.38it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A#015 67%|██████▋   | 877/1314 [07:37<41:48,  5.74s/it]#015 67%|██████▋   | 878/1314 [07:38<30:13,  4.16s/it]#015 67%|██████▋   | 879/1314 [07:38<22:09,  3.06s/it]#015 67%|██████▋   | 880/1314 [07:39<16:31,  2.28s/it]#015 67%|██████▋   | 881/1314 [07:39<12:34,  1.74s/it]#015 67%|██████▋   | 882/1314 [07:40<09:48,  1.36s/it]#015 67%|██████▋   | 883/1314 [07:40<07:52,  1.10s/it]#015 67%|██████▋   | 884/1314 [07:41<06:31,  1.10it/s]#015 67%|██████▋   | 885/1314 [07:41<05:34,  1.28it/s]#015 67%|██████▋   | 886/1314 [07:42<04:55,  1.45it/s]#015 68%|██████▊   | 887/1314 [07:42<04:27,  1.59it/s]#015 68%|██████▊   | 888/1314 [07:43<04:07,  1.72it/s]#015 68%|██████▊   | 889/1314 [07:43<03:53,  1.82it/s]#015 68%|██████▊   | 890/1314 [07:44<03:44,  1.89it/s]#015 68%|██████▊   | 891/1314 [07:44<03:38,  1.94it/s]#015 68%|██████▊   | 892/1314 [07:45<03:32,  1.99it/s]#015 68%|██████▊   | 893/1314 [07:45<03:28,  2.02it/s]#015 68%|██████▊   | 894/1314 [07:46<03:25,  2.05it/s]#015 68%|██████▊   | 895/1314 [07:46<03:22,  2.07it/s]#015 68%|██████▊   | 896/1314 [07:47<03:21,  2.08it/s]#015 68%|██████▊   | 897/1314 [07:47<03:19,  2.09it/s]#015 68%|██████▊   | 898/1314 [07:47<03:19,  2.09it/s]#015 68%|██████▊   | 899/1314 [07:48<03:18,  2.09it/s]#015 68%|██████▊   | 900/1314 [07:48<03:17,  2.09it/s]#015 69%|██████▊   | 901/1314 [07:49<03:17,  2.10it/s]#015 69%|██████▊   | 902/1314 [07:49<03:17,  2.09it/s]#015 69%|██████▊   | 903/1314 [07:50<03:16,  2.10it/s]#015 69%|██████▉   | 904/1314 [07:50<03:16,  2.09it/s]#015 69%|██████▉   | 905/1314 [07:51<03:15,  2.09it/s]#015 69%|██████▉   | 906/1314 [07:51<03:14,  2.10it/s]#015 69%|██████▉   | 907/1314 [07:52<03:13,  2.10it/s]#015 69%|██████▉   | 908/1314 [07:52<03:13,  2.10it/s]#015 69%|██████▉   | 909/1314 [07:53<03:13,  2.10it/s]#015 69%|██████▉   | 910/1314 [07:53<03:12,  2.10it/s]#015 69%|██████▉   | 911/1314 [07:54<03:12,  2.10it/s]#015 69%|██████▉   | 912/1314 [07:54<03:12,  2.09it/s]#015 69%|██████▉   | 913/1314 [07:55<03:11,  2.09it/s]#015 70%|██████▉   | 914/1314 [07:55<03:11,  2.09it/s]#015 70%|██████▉   | 915/1314 [07:56<03:11,  2.09it/s]#015 70%|██████▉   | 916/1314 [07:56<03:10,  2.09it/s]#015 70%|██████▉   | 917/1314 [07:57<03:09,  2.09it/s]#015 70%|██████▉   | 918/1314 [07:57<03:09,  2.09it/s]#015 70%|██████▉   | 919/1314 [07:58<03:09,  2.08it/s]#015 70%|███████   | 920/1314 [07:58<03:09,  2.07it/s]#015 70%|███████   | 921/1314 [07:58<03:09,  2.07it/s]#015 70%|███████   | 922/1314 [07:59<03:08,  2.08it/s]#015 70%|███████   | 923/1314 [07:59<03:08,  2.08it/s]#015 70%|███████   | 924/1314 [08:00<03:07,  2.08it/s]#015 70%|███████   | 925/1314 [08:00<03:07,  2.07it/s]#015 70%|███████   | 926/1314 [08:01<03:06,  2.08it/s]#015 71%|███████   | 927/1314 [08:01<03:06,  2.08it/s]#015 71%|███████   | 928/1314 [08:02<03:05,  2.08it/s]#015 71%|███████   | 929/1314 [08:02<03:05,  2.08it/s]#015 71%|███████   | 930/1314 [08:03<03:05,  2.07it/s]#015 71%|███████   | 931/1314 [08:03<03:04,  2.07it/s]#015 71%|███████   | 932/1314 [08:04<03:03,  2.08it/s]#015 71%|███████   | 933/1314 [08:04<03:03,  2.08it/s]#015 71%|███████   | 934/1314 [08:05<03:02,  2.08it/s]#015 71%|███████   | 935/1314 [08:05<03:01,  2.08it/s]#015 71%|███████   | 936/1314 [08:06<03:01,  2.08it/s]#015 71%|███████▏  | 937/1314 [08:06<03:01,  2.08it/s]#015 71%|███████▏  | 938/1314 [08:07<03:01,  2.07it/s]#015 71%|███████▏  | 939/1314 [08:07<03:00,  2.08it/s]#015 72%|███████▏  | 940/1314 [08:08<02:59,  2.09it/s]#015 72%|███████▏  | 941/1314 [08:08<02:58,  2.09it/s]#015 72%|███████▏  | 942/1314 [08:09<02:57,  2.10it/s]#015 72%|███████▏  | 943/1314 [08:09<02:57,  2.10it/s]#015 72%|███████▏  | 944/1314 [08:10<02:57,  2.09it/s]#015 72%|███████▏  | 945/1314 [08:10<02:56,  2.09it/s]#015 72%|███████▏  | 946/1314 [08:10<02:55,  2.10it/s]#015 72%|███████▏  | 947/1314 [08:11<02:55,  2.09it/s]#015 72%|███████▏  | 948/1314 [08:11<02:55,  2.09it/s]#015 72%|███████▏  | 949/1314 [08:12<02:54,  2.09it/s]#015 72%|███████▏  | 950/1314 [08:12<02:53,  2.09it/s]#015 72%|███████▏  | 951/1314 [08:13<02:53,  2.09it/s]#015 72%|███████▏  | 952/1314 [08:13<02:53,  2.09it/s]#015 73%|███████▎  | 953/1314 [08:14<02:53,  2.09it/s]#015 73%|███████▎  | 954/1314 [08:14<02:52,  2.09it/s]#015 73%|███████▎  | 955/1314 [08:15<02:51,  2.09it/s]#015 73%|███████▎  | 956/1314 [08:15<02:50,  2.09it/s]#015 73%|███████▎  | 957/1314 [08:16<02:50,  2.09it/s]#015 73%|███████▎  | 958/1314 [08:16<02:49,  2.10it/s]#015 73%|███████▎  | 959/1314 [08:17<02:49,  2.10it/s]#015 73%|███████▎  | 960/1314 [08:17<02:49,  2.09it/s]#015 73%|███████▎  | 961/1314 [08:18<02:49,  2.08it/s]#015 73%|███████▎  | 962/1314 [08:18<02:48,  2.09it/s]#015 73%|███████▎  | 963/1314 [08:19<02:47,  2.09it/s]#015 73%|███████▎  | 964/1314 [08:19<02:46,  2.10it/s]#015 73%|███████▎  | 965/1314 [08:20<02:46,  2.10it/s]#015 74%|███████▎  | 966/1314 [08:20<02:45,  2.10it/s]#015 74%|███████▎  | 967/1314 [08:21<02:45,  2.09it/s]#015 74%|███████▎  | 968/1314 [08:21<02:45,  2.10it/s]#015 74%|███████▎  | 969/1314 [08:21<02:44,  2.09it/s]#015 74%|███████▍  | 970/1314 [08:22<02:44,  2.09it/s]#015 74%|███████▍  | 971/1314 [08:22<02:44,  2.08it/s]#015 74%|███████▍  | 972/1314 [08:23<02:43,  2.09it/s]#015 74%|███████▍  | 973/1314 [08:23<02:43,  2.09it/s]#015 74%|███████▍  | 974/1314 [08:24<02:42,  2.09it/s]#015 74%|███████▍  | 975/1314 [08:24<02:42,  2.09it/s]#015 74%|███████▍  | 976/1314 [08:25<02:41,  2.09it/s]#015 74%|███████▍  | 977/1314 [08:25<02:41,  2.09it/s]#015 74%|███████▍  | 978/1314 [08:26<02:40,  2.09it/s]#015 75%|███████▍  | 979/1314 [08:26<02:39,  2.09it/s]#015 75%|███████▍  | 980/1314 [08:27<02:39,  2.10it/s]#015 75%|███████▍  | 981/1314 [08:27<02:38,  2.10it/s]#015 75%|███████▍  | 982/1314 [08:28<02:38,  2.10it/s]#015 75%|███████▍  | 983/1314 [08:28<02:37,  2.10it/s]#015 75%|███████▍  | 984/1314 [08:29<02:37,  2.10it/s]#015 75%|███████▍  | 985/1314 [08:29<02:36,  2.10it/s]#015 75%|███████▌  | 986/1314 [08:30<02:36,  2.10it/s]#015 75%|███████▌  | 987/1314 [08:30<02:35,  2.10it/s]#015 75%|███████▌  | 988/1314 [08:31<02:35,  2.10it/s]#015 75%|███████▌  | 989/1314 [08:31<02:34,  2.10it/s]#015 75%|███████▌  | 990/1314 [08:32<02:34,  2.10it/s]#015 75%|███████▌  | 991/1314 [08:32<02:33,  2.10it/s]#015 75%|███████▌  | 992/1314 [08:32<02:33,  2.09it/s]#015 76%|███████▌  | 993/1314 [08:33<02:33,  2.09it/s]#015 76%|███████▌  | 994/1314 [08:33<02:32,  2.10it/s]#015 76%|███████▌  | 995/1314 [08:34<02:32,  2.09it/s]#015 76%|███████▌  | 996/1314 [08:34<02:32,  2.09it/s]#015 76%|███████▌  | 997/1314 [08:35<02:31,  2.09it/s]#015 76%|███████▌  | 998/1314 [08:35<02:30,  2.10it/s]#015 76%|███████▌  | 999/1314 [08:36<02:30,  2.10it/s]#015 76%|███████▌  | 1000/1314 [08:36<02:29,  2.10it/s]#015                                                   #015#015 76%|███████▌  | 1000/1314 [08:36<02:29,  2.10it/s]Saving model checkpoint to /opt/ml/model/checkpoint-1000\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/checkpoint-1000/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/checkpoint-1000/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/checkpoint-1000/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/checkpoint-1000/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m#015 76%|███████▌  | 1001/1314 [08:38<04:50,  1.08it/s]#015 76%|███████▋  | 1002/1314 [08:39<04:07,  1.26it/s]#015 76%|███████▋  | 1003/1314 [08:39<03:37,  1.43it/s]#015 76%|███████▋  | 1004/1314 [08:40<03:16,  1.58it/s]#015 76%|███████▋  | 1005/1314 [08:40<03:01,  1.70it/s]#015 77%|███████▋  | 1006/1314 [08:41<02:51,  1.80it/s]#015 77%|███████▋  | 1007/1314 [08:41<02:43,  1.88it/s]#015 77%|███████▋  | 1008/1314 [08:42<02:37,  1.94it/s]#015 77%|███████▋  | 1009/1314 [08:42<02:33,  1.98it/s]#015 77%|███████▋  | 1010/1314 [08:43<02:31,  2.01it/s]#015 77%|███████▋  | 1011/1314 [08:43<02:28,  2.04it/s]#015 77%|███████▋  | 1012/1314 [08:44<02:26,  2.06it/s]#015 77%|███████▋  | 1013/1314 [08:44<02:25,  2.07it/s]#015 77%|███████▋  | 1014/1314 [08:44<02:24,  2.07it/s]#015 77%|███████▋  | 1015/1314 [08:45<02:23,  2.08it/s]#015 77%|███████▋  | 1016/1314 [08:45<02:22,  2.09it/s]#015 77%|███████▋  | 1017/1314 [08:46<02:21,  2.09it/s]#015 77%|███████▋  | 1018/1314 [08:46<02:20,  2.10it/s]#015 78%|███████▊  | 1019/1314 [08:47<02:20,  2.10it/s]#015 78%|███████▊  | 1020/1314 [08:47<02:19,  2.10it/s]#015 78%|███████▊  | 1021/1314 [08:48<02:19,  2.09it/s]#015 78%|███████▊  | 1022/1314 [08:48<02:19,  2.10it/s]#015 78%|███████▊  | 1023/1314 [08:49<02:19,  2.09it/s]#015 78%|███████▊  | 1024/1314 [08:49<02:18,  2.09it/s]#015 78%|███████▊  | 1025/1314 [08:50<02:18,  2.09it/s]#015 78%|███████▊  | 1026/1314 [08:50<02:17,  2.09it/s]#015 78%|███████▊  | 1027/1314 [08:51<02:17,  2.09it/s]#015 78%|███████▊  | 1028/1314 [08:51<02:16,  2.10it/s]#015 78%|███████▊  | 1029/1314 [08:52<02:15,  2.10it/s]#015 78%|███████▊  | 1030/1314 [08:52<02:15,  2.10it/s]#015 78%|███████▊  | 1031/1314 [08:53<02:14,  2.10it/s]#015 79%|███████▊  | 1032/1314 [08:53<02:14,  2.10it/s]#015 79%|███████▊  | 1033/1314 [08:54<02:14,  2.09it/s]#015 79%|███████▊  | 1034/1314 [08:54<02:14,  2.08it/s]#015 79%|███████▉  | 1035/1314 [08:55<02:15,  2.07it/s]#015 79%|███████▉  | 1036/1314 [08:55<02:14,  2.07it/s]#015 79%|███████▉  | 1037/1314 [08:55<02:13,  2.07it/s]#015 79%|███████▉  | 1038/1314 [08:56<02:12,  2.08it/s]#015 79%|███████▉  | 1039/1314 [08:56<02:12,  2.07it/s]#015 79%|███████▉  | 1040/1314 [08:57<02:11,  2.08it/s]#015 79%|███████▉  | 1041/1314 [08:57<02:10,  2.09it/s]#015 79%|███████▉  | 1042/1314 [08:58<02:10,  2.08it/s]#015 79%|███████▉  | 1043/1314 [08:58<02:09,  2.09it/s]#015 79%|███████▉  | 1044/1314 [08:59<02:09,  2.09it/s]#015 80%|███████▉  | 1045/1314 [08:59<02:08,  2.09it/s]#015 80%|███████▉  | 1046/1314 [09:00<02:08,  2.09it/s]#015 80%|███████▉  | 1047/1314 [09:00<02:07,  2.09it/s]#015 80%|███████▉  | 1048/1314 [09:01<02:07,  2.09it/s]#015 80%|███████▉  | 1049/1314 [09:01<02:07,  2.08it/s]#015 80%|███████▉  | 1050/1314 [09:02<02:06,  2.09it/s]#015 80%|███████▉  | 1051/1314 [09:02<02:05,  2.09it/s]#015 80%|████████  | 1052/1314 [09:03<02:04,  2.10it/s]#015 80%|████████  | 1053/1314 [09:03<02:04,  2.09it/s]#015 80%|████████  | 1054/1314 [09:04<02:04,  2.09it/s]#015 80%|████████  | 1055/1314 [09:04<02:04,  2.08it/s]#015 80%|████████  | 1056/1314 [09:05<02:04,  2.08it/s]#015 80%|████████  | 1057/1314 [09:05<02:03,  2.08it/s]#015 81%|████████  | 1058/1314 [09:06<02:03,  2.08it/s]#015 81%|████████  | 1059/1314 [09:06<02:02,  2.08it/s]#015 81%|████████  | 1060/1314 [09:07<02:02,  2.07it/s]#015 81%|████████  | 1061/1314 [09:07<02:02,  2.07it/s]#015 81%|████████  | 1062/1314 [09:07<02:01,  2.08it/s]#015 81%|████████  | 1063/1314 [09:08<02:00,  2.08it/s]#015 81%|████████  | 1064/1314 [09:08<02:00,  2.08it/s]#015 81%|████████  | 1065/1314 [09:09<01:59,  2.08it/s]#015 81%|████████  | 1066/1314 [09:09<01:58,  2.09it/s]#015 81%|████████  | 1067/1314 [09:10<01:58,  2.08it/s]#015 81%|████████▏ | 1068/1314 [09:10<01:58,  2.08it/s]#015 81%|████████▏ | 1069/1314 [09:11<01:57,  2.08it/s]#015 81%|████████▏ | 1070/1314 [09:11<01:57,  2.08it/s]#015 82%|████████▏ | 1071/1314 [09:12<01:56,  2.08it/s]#015 82%|████████▏ | 1072/1314 [09:12<01:56,  2.08it/s]#015 82%|████████▏ | 1073/1314 [09:13<01:55,  2.09it/s]#015 82%|████████▏ | 1074/1314 [09:13<01:54,  2.09it/s]#015 82%|████████▏ | 1075/1314 [09:14<01:55,  2.08it/s]#015 82%|████████▏ | 1076/1314 [09:14<01:55,  2.07it/s]#015 82%|████████▏ | 1077/1314 [09:15<01:54,  2.07it/s]#015 82%|████████▏ | 1078/1314 [09:15<01:53,  2.07it/s]#015 82%|████████▏ | 1079/1314 [09:16<01:53,  2.07it/s]#015 82%|████████▏ | 1080/1314 [09:16<01:52,  2.07it/s]#015 82%|████████▏ | 1081/1314 [09:17<01:52,  2.08it/s]#015 82%|████████▏ | 1082/1314 [09:17<01:52,  2.07it/s]#015 82%|████████▏ | 1083/1314 [09:18<01:51,  2.07it/s]#015 82%|████████▏ | 1084/1314 [09:18<01:50,  2.08it/s]#015 83%|████████▎ | 1085/1314 [09:19<01:49,  2.09it/s]#015 83%|████████▎ | 1086/1314 [09:19<01:48,  2.09it/s]#015 83%|████████▎ | 1087/1314 [09:19<01:48,  2.10it/s]#015 83%|████████▎ | 1088/1314 [09:20<01:47,  2.09it/s]#015 83%|████████▎ | 1089/1314 [09:20<01:47,  2.09it/s]#015 83%|████████▎ | 1090/1314 [09:21<01:47,  2.09it/s]#015 83%|████████▎ | 1091/1314 [09:21<01:46,  2.09it/s]#015 83%|████████▎ | 1092/1314 [09:22<01:46,  2.09it/s]#015 83%|████████▎ | 1093/1314 [09:22<01:45,  2.09it/s]#015 83%|████████▎ | 1094/1314 [09:23<01:45,  2.09it/s]#015 83%|████████▎ | 1095/1314 [09:23<01:44,  2.09it/s]#015 83%|████████▎ | 1096/1314 [09:24<01:44,  2.09it/s]#015 83%|████████▎ | 1097/1314 [09:24<01:43,  2.09it/s]#015 84%|████████▎ | 1098/1314 [09:25<01:43,  2.09it/s]#015 84%|████████▎ | 1099/1314 [09:25<01:42,  2.09it/s]#015 84%|████████▎ | 1100/1314 [09:26<01:42,  2.09it/s]#015 84%|████████▍ | 1101/1314 [09:26<01:41,  2.10it/s]#015 84%|████████▍ | 1102/1314 [09:27<01:41,  2.10it/s]#015 84%|████████▍ | 1103/1314 [09:27<01:40,  2.09it/s]#015 84%|████████▍ | 1104/1314 [09:28<01:40,  2.10it/s]#015 84%|████████▍ | 1105/1314 [09:28<01:39,  2.10it/s]#015 84%|████████▍ | 1106/1314 [09:29<01:38,  2.10it/s]#015 84%|████████▍ | 1107/1314 [09:29<01:38,  2.10it/s]#015 84%|████████▍ | 1108/1314 [09:30<01:37,  2.10it/s]#015 84%|████████▍ | 1109/1314 [09:30<01:37,  2.11it/s]#015 84%|████████▍ | 1110/1314 [09:30<01:36,  2.10it/s]#015 85%|████████▍ | 1111/1314 [09:31<01:36,  2.10it/s]#015 85%|████████▍ | 1112/1314 [09:31<01:36,  2.10it/s]#015 85%|████████▍ | 1113/1314 [09:32<01:35,  2.10it/s]#015 85%|████████▍ | 1114/1314 [09:32<01:35,  2.10it/s]#015 85%|████████▍ | 1115/1314 [09:33<01:34,  2.10it/s]#015 85%|████████▍ | 1116/1314 [09:33<01:34,  2.10it/s]#015 85%|████████▌ | 1117/1314 [09:34<01:33,  2.10it/s]#015 85%|████████▌ | 1118/1314 [09:34<01:33,  2.09it/s]#015 85%|████████▌ | 1119/1314 [09:35<01:33,  2.09it/s]#015 85%|████████▌ | 1120/1314 [09:35<01:32,  2.09it/s]#015 85%|████████▌ | 1121/1314 [09:36<01:32,  2.09it/s]#015 85%|████████▌ | 1122/1314 [09:36<01:31,  2.09it/s]#015 85%|████████▌ | 1123/1314 [09:37<01:31,  2.08it/s]#015 86%|████████▌ | 1124/1314 [09:37<01:31,  2.08it/s]#015 86%|████████▌ | 1125/1314 [09:38<01:30,  2.08it/s]#015 86%|████████▌ | 1126/1314 [09:38<01:30,  2.08it/s]#015 86%|████████▌ | 1127/1314 [09:39<01:29,  2.08it/s]#015 86%|████████▌ | 1128/1314 [09:39<01:29,  2.09it/s]#015 86%|████████▌ | 1129/1314 [09:40<01:28,  2.09it/s]#015 86%|████████▌ | 1130/1314 [09:40<01:27,  2.09it/s]#015 86%|████████▌ | 1131/1314 [09:41<01:27,  2.09it/s]#015 86%|████████▌ | 1132/1314 [09:41<01:27,  2.08it/s]#015 86%|████████▌ | 1133/1314 [09:41<01:26,  2.09it/s]#015 86%|████████▋ | 1134/1314 [09:42<01:26,  2.08it/s]#015 86%|████████▋ | 1135/1314 [09:42<01:26,  2.08it/s]#015 86%|████████▋ | 1136/1314 [09:43<01:25,  2.09it/s]#015 87%|████████▋ | 1137/1314 [09:43<01:24,  2.09it/s]#015 87%|████████▋ | 1138/1314 [09:44<01:24,  2.09it/s]#015 87%|████████▋ | 1139/1314 [09:44<01:23,  2.09it/s]#015 87%|████████▋ | 1140/1314 [09:45<01:23,  2.09it/s]#015 87%|████████▋ | 1141/1314 [09:45<01:22,  2.09it/s]#015 87%|████████▋ | 1142/1314 [09:46<01:22,  2.08it/s]#015 87%|████████▋ | 1143/1314 [09:46<01:22,  2.08it/s]#015 87%|████████▋ | 1144/1314 [09:47<01:21,  2.08it/s]#015 87%|████████▋ | 1145/1314 [09:47<01:21,  2.08it/s]#015 87%|████████▋ | 1146/1314 [09:48<01:21,  2.07it/s]#015 87%|████████▋ | 1147/1314 [09:48<01:20,  2.08it/s]#015 87%|████████▋ | 1148/1314 [09:49<01:19,  2.08it/s]#015 87%|████████▋ | 1149/1314 [09:49<01:19,  2.09it/s]#015 88%|████████▊ | 1150/1314 [09:50<01:18,  2.09it/s]#015 88%|████████▊ | 1151/1314 [09:50<01:17,  2.09it/s]#015 88%|████████▊ | 1152/1314 [09:51<01:17,  2.09it/s]#015 88%|████████▊ | 1153/1314 [09:51<01:17,  2.09it/s]#015 88%|████████▊ | 1154/1314 [09:52<01:16,  2.08it/s]#015 88%|████████▊ | 1155/1314 [09:52<01:16,  2.09it/s]#015 88%|████████▊ | 1156/1314 [09:52<01:15,  2.09it/s]#015 88%|████████▊ | 1157/1314 [09:53<01:14,  2.10it/s]#015 88%|████████▊ | 1158/1314 [09:53<01:14,  2.09it/s]#015 88%|████████▊ | 1159/1314 [09:54<01:14,  2.09it/s]#015 88%|████████▊ | 1160/1314 [09:54<01:13,  2.09it/s]#015 88%|████████▊ | 1161/1314 [09:55<01:13,  2.09it/s]#015 88%|████████▊ | 1162/1314 [09:55<01:12,  2.09it/s]#015 89%|████████▊ | 1163/1314 [09:56<01:12,  2.09it/s]#015 89%|████████▊ | 1164/1314 [09:56<01:11,  2.10it/s]#015 89%|████████▊ | 1165/1314 [09:57<01:11,  2.10it/s]#015 89%|████████▊ | 1166/1314 [09:57<01:10,  2.09it/s]#015 89%|████████▉ | 1167/1314 [09:58<01:10,  2.09it/s]#015 89%|████████▉ | 1168/1314 [09:58<01:10,  2.08it/s]#015 89%|████████▉ | 1169/1314 [09:59<01:09,  2.08it/s]#015 89%|████████▉ | 1170/1314 [09:59<01:09,  2.08it/s]#015 89%|████████▉ | 1171/1314 [10:00<01:08,  2.09it/s]#015 89%|████████▉ | 1172/1314 [10:00<01:07,  2.09it/s]#015 89%|████████▉ | 1173/1314 [10:01<01:07,  2.10it/s]#015 89%|████████▉ | 1174/1314 [10:01<01:06,  2.10it/s]#015 89%|████████▉ | 1175/1314 [10:02<01:06,  2.10it/s]#015 89%|████████▉ | 1176/1314 [10:02<01:05,  2.11it/s]#015 90%|████████▉ | 1177/1314 [10:03<01:05,  2.10it/s]#015 90%|████████▉ | 1178/1314 [10:03<01:04,  2.10it/s]#015 90%|████████▉ | 1179/1314 [10:03<01:04,  2.10it/s]#015 90%|████████▉ | 1180/1314 [10:04<01:03,  2.09it/s]#015 90%|████████▉ | 1181/1314 [10:04<01:03,  2.10it/s]#015 90%|████████▉ | 1182/1314 [10:05<01:02,  2.10it/s]#015 90%|█████████ | 1183/1314 [10:05<01:02,  2.10it/s]#015 90%|█████████ | 1184/1314 [10:06<01:01,  2.11it/s]#015 90%|█████████ | 1185/1314 [10:06<01:01,  2.11it/s]#015 90%|█████████ | 1186/1314 [10:07<01:00,  2.11it/s]#015 90%|█████████ | 1187/1314 [10:07<01:00,  2.11it/s]#015 90%|█████████ | 1188/1314 [10:08<00:59,  2.11it/s]#015 90%|█████████ | 1189/1314 [10:08<00:59,  2.11it/s]#015 91%|█████████ | 1190/1314 [10:09<00:58,  2.11it/s]#015 91%|█████████ | 1191/1314 [10:09<00:58,  2.10it/s]#015 91%|█████████ | 1192/1314 [10:10<00:57,  2.11it/s]#015 91%|█████████ | 1193/1314 [10:10<00:57,  2.10it/s]#015 91%|█████████ | 1194/1314 [10:11<00:57,  2.10it/s]#015 91%|█████████ | 1195/1314 [10:11<00:56,  2.11it/s]#015 91%|█████████ | 1196/1314 [10:12<00:55,  2.11it/s]#015 91%|█████████ | 1197/1314 [10:12<00:55,  2.11it/s]#015 91%|█████████ | 1198/1314 [10:12<00:55,  2.11it/s]#015 91%|█████████ | 1199/1314 [10:13<00:54,  2.11it/s]#015 91%|█████████▏| 1200/1314 [10:13<00:53,  2.11it/s]#015 91%|█████████▏| 1201/1314 [10:14<00:53,  2.11it/s]#015 91%|█████████▏| 1202/1314 [10:14<00:53,  2.11it/s]#015 92%|█████████▏| 1203/1314 [10:15<00:52,  2.11it/s]#015 92%|█████████▏| 1204/1314 [10:15<00:52,  2.11it/s]#015 92%|█████████▏| 1205/1314 [10:16<00:51,  2.11it/s]#015 92%|█████████▏| 1206/1314 [10:16<00:51,  2.10it/s]#015 92%|█████████▏| 1207/1314 [10:17<00:51,  2.10it/s]#015 92%|█████████▏| 1208/1314 [10:17<00:50,  2.08it/s]#015 92%|█████████▏| 1209/1314 [10:18<00:50,  2.08it/s]#015 92%|█████████▏| 1210/1314 [10:18<00:50,  2.08it/s]#015 92%|█████████▏| 1211/1314 [10:19<00:49,  2.08it/s]#015 92%|█████████▏| 1212/1314 [10:19<00:48,  2.08it/s]#015 92%|█████████▏| 1213/1314 [10:20<00:48,  2.09it/s]#015 92%|█████████▏| 1214/1314 [10:20<00:47,  2.09it/s]#015 92%|█████████▏| 1215/1314 [10:21<00:47,  2.10it/s]#015 93%|█████████▎| 1216/1314 [10:21<00:46,  2.10it/s]#015 93%|█████████▎| 1217/1314 [10:22<00:46,  2.09it/s]#015 93%|█████████▎| 1218/1314 [10:22<00:46,  2.09it/s]#015 93%|█████████▎| 1219/1314 [10:23<00:45,  2.08it/s]#015 93%|█████████▎| 1220/1314 [10:23<00:45,  2.08it/s]#015 93%|█████████▎| 1221/1314 [10:23<00:44,  2.09it/s]#015 93%|█████████▎| 1222/1314 [10:24<00:44,  2.09it/s]#015 93%|█████████▎| 1223/1314 [10:24<00:43,  2.09it/s]#015 93%|█████████▎| 1224/1314 [10:25<00:42,  2.09it/s]#015 93%|█████████▎| 1225/1314 [10:25<00:42,  2.10it/s]#015 93%|█████████▎| 1226/1314 [10:26<00:41,  2.10it/s]#015 93%|█████████▎| 1227/1314 [10:26<00:41,  2.09it/s]#015 93%|█████████▎| 1228/1314 [10:27<00:40,  2.10it/s]#015 94%|█████████▎| 1229/1314 [10:27<00:40,  2.10it/s]#015 94%|█████████▎| 1230/1314 [10:28<00:39,  2.10it/s]#015 94%|█████████▎| 1231/1314 [10:28<00:39,  2.09it/s]#015 94%|█████████▍| 1232/1314 [10:29<00:39,  2.10it/s]#015 94%|█████████▍| 1233/1314 [10:29<00:38,  2.10it/s]#015 94%|█████████▍| 1234/1314 [10:30<00:38,  2.10it/s]#015 94%|█████████▍| 1235/1314 [10:30<00:37,  2.10i\u001b[0m\n",
      "\u001b[34mt/s]#015 94%|█████████▍| 1236/1314 [10:31<00:37,  2.10it/s]#015 94%|█████████▍| 1237/1314 [10:31<00:36,  2.10it/s]#015 94%|█████████▍| 1238/1314 [10:32<00:36,  2.10it/s]#015 94%|█████████▍| 1239/1314 [10:32<00:35,  2.10it/s]#015 94%|█████████▍| 1240/1314 [10:33<00:35,  2.10it/s]#015 94%|█████████▍| 1241/1314 [10:33<00:34,  2.10it/s]#015 95%|█████████▍| 1242/1314 [10:33<00:34,  2.10it/s]#015 95%|█████████▍| 1243/1314 [10:34<00:33,  2.10it/s]#015 95%|█████████▍| 1244/1314 [10:34<00:33,  2.11it/s]#015 95%|█████████▍| 1245/1314 [10:35<00:32,  2.10it/s]#015 95%|█████████▍| 1246/1314 [10:35<00:32,  2.09it/s]#015 95%|█████████▍| 1247/1314 [10:36<00:32,  2.09it/s]#015 95%|█████████▍| 1248/1314 [10:36<00:31,  2.09it/s]#015 95%|█████████▌| 1249/1314 [10:37<00:31,  2.09it/s]#015 95%|█████████▌| 1250/1314 [10:37<00:30,  2.09it/s]#015 95%|█████████▌| 1251/1314 [10:38<00:30,  2.09it/s]#015 95%|█████████▌| 1252/1314 [10:38<00:29,  2.09it/s]#015 95%|█████████▌| 1253/1314 [10:39<00:29,  2.08it/s]#015 95%|█████████▌| 1254/1314 [10:39<00:28,  2.08it/s]#015 96%|█████████▌| 1255/1314 [10:40<00:28,  2.09it/s]#015 96%|█████████▌| 1256/1314 [10:40<00:27,  2.09it/s]#015 96%|█████████▌| 1257/1314 [10:41<00:27,  2.10it/s]#015 96%|█████████▌| 1258/1314 [10:41<00:26,  2.10it/s]#015 96%|█████████▌| 1259/1314 [10:42<00:26,  2.10it/s]#015 96%|█████████▌| 1260/1314 [10:42<00:25,  2.10it/s]#015 96%|█████████▌| 1261/1314 [10:43<00:25,  2.10it/s]#015 96%|█████████▌| 1262/1314 [10:43<00:24,  2.09it/s]#015 96%|█████████▌| 1263/1314 [10:44<00:24,  2.09it/s]#015 96%|█████████▌| 1264/1314 [10:44<00:23,  2.10it/s]#015 96%|█████████▋| 1265/1314 [10:44<00:23,  2.10it/s]#015 96%|█████████▋| 1266/1314 [10:45<00:22,  2.10it/s]#015 96%|█████████▋| 1267/1314 [10:45<00:22,  2.10it/s]#015 96%|█████████▋| 1268/1314 [10:46<00:21,  2.10it/s]#015 97%|█████████▋| 1269/1314 [10:46<00:21,  2.10it/s]#015 97%|█████████▋| 1270/1314 [10:47<00:20,  2.10it/s]#015 97%|█████████▋| 1271/1314 [10:47<00:20,  2.10it/s]#015 97%|█████████▋| 1272/1314 [10:48<00:20,  2.10it/s]#015 97%|█████████▋| 1273/1314 [10:48<00:19,  2.10it/s]#015 97%|█████████▋| 1274/1314 [10:49<00:19,  2.10it/s]#015 97%|█████████▋| 1275/1314 [10:49<00:18,  2.10it/s]#015 97%|█████████▋| 1276/1314 [10:50<00:18,  2.09it/s]#015 97%|█████████▋| 1277/1314 [10:50<00:17,  2.10it/s]#015 97%|█████████▋| 1278/1314 [10:51<00:17,  2.10it/s]#015 97%|█████████▋| 1279/1314 [10:51<00:16,  2.10it/s]#015 97%|█████████▋| 1280/1314 [10:52<00:16,  2.09it/s]#015 97%|█████████▋| 1281/1314 [10:52<00:15,  2.09it/s]#015 98%|█████████▊| 1282/1314 [10:53<00:15,  2.09it/s]#015 98%|█████████▊| 1283/1314 [10:53<00:14,  2.10it/s]#015 98%|█████████▊| 1284/1314 [10:54<00:14,  2.10it/s]#015 98%|█████████▊| 1285/1314 [10:54<00:13,  2.09it/s]#015 98%|█████████▊| 1286/1314 [10:54<00:13,  2.09it/s]#015 98%|█████████▊| 1287/1314 [10:55<00:12,  2.09it/s]#015 98%|█████████▊| 1288/1314 [10:55<00:12,  2.09it/s]#015 98%|█████████▊| 1289/1314 [10:56<00:11,  2.09it/s]#015 98%|█████████▊| 1290/1314 [10:56<00:11,  2.09it/s]#015 98%|█████████▊| 1291/1314 [10:57<00:11,  2.08it/s]#015 98%|█████████▊| 1292/1314 [10:57<00:10,  2.08it/s]#015 98%|█████████▊| 1293/1314 [10:58<00:10,  2.08it/s]#015 98%|█████████▊| 1294/1314 [10:58<00:09,  2.08it/s]#015 99%|█████████▊| 1295/1314 [10:59<00:09,  2.08it/s]#015 99%|█████████▊| 1296/1314 [10:59<00:08,  2.08it/s]#015 99%|█████████▊| 1297/1314 [11:00<00:08,  2.09it/s]#015 99%|█████████▉| 1298/1314 [11:00<00:07,  2.10it/s]#015 99%|█████████▉| 1299/1314 [11:01<00:07,  2.10it/s]#015 99%|█████████▉| 1300/1314 [11:01<00:06,  2.11it/s]#015 99%|█████████▉| 1301/1314 [11:02<00:06,  2.11it/s]#015 99%|█████████▉| 1302/1314 [11:02<00:05,  2.11it/s]#015 99%|█████████▉| 1303/1314 [11:03<00:05,  2.11it/s]#015 99%|█████████▉| 1304/1314 [11:03<00:04,  2.03it/s]#015 99%|█████████▉| 1305/1314 [11:04<00:04,  2.05it/s]#015 99%|█████████▉| 1306/1314 [11:04<00:03,  2.07it/s]#015 99%|█████████▉| 1307/1314 [11:05<00:03,  2.08it/s]#015100%|█████████▉| 1308/1314 [11:05<00:02,  2.09it/s]#015100%|█████████▉| 1309/1314 [11:06<00:02,  2.10it/s]#015100%|█████████▉| 1310/1314 [11:06<00:01,  2.10it/s]#015100%|█████████▉| 1311/1314 [11:06<00:01,  2.10it/s]#015100%|█████████▉| 1312/1314 [11:07<00:00,  2.11it/s]#015100%|█████████▉| 1313/1314 [11:07<00:00,  2.11it/s]#015100%|██████████| 1314/1314 [11:08<00:00,  2.50it/s]The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 3500\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/55 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  4%|▎         | 2/55 [00:00<00:08,  6.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  5%|▌         | 3/55 [00:00<00:11,  4.35it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  7%|▋         | 4/55 [00:00<00:13,  3.79it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015  9%|▉         | 5/55 [00:01<00:14,  3.51it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 11%|█         | 6/55 [00:01<00:14,  3.35it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 13%|█▎        | 7/55 [00:01<00:14,  3.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 15%|█▍        | 8/55 [00:02<00:14,  3.22it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 16%|█▋        | 9/55 [00:02<00:14,  3.18it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 18%|█▊        | 10/55 [00:02<00:14,  3.16it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 20%|██        | 11/55 [00:03<00:14,  3.13it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 22%|██▏       | 12/55 [00:03<00:13,  3.12it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 24%|██▎       | 13/55 [00:03<00:13,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 25%|██▌       | 14/55 [00:04<00:13,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 27%|██▋       | 15/55 [00:04<00:12,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 29%|██▉       | 16/55 [00:04<00:12,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 31%|███       | 17/55 [00:05<00:12,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 33%|███▎      | 18/55 [00:05<00:11,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 35%|███▍      | 19/55 [00:05<00:11,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 36%|███▋      | 20/55 [00:06<00:11,  3.12it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 38%|███▊      | 21/55 [00:06<00:10,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 40%|████      | 22/55 [00:06<00:10,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 42%|████▏     | 23/55 [00:07<00:10,  3.11it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 44%|████▎     | 24/55 [00:07<00:10,  3.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 45%|████▌     | 25/55 [00:07<00:09,  3.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 47%|████▋     | 26/55 [00:08<00:09,  3.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 49%|████▉     | 27/55 [00:08<00:09,  3.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 51%|█████     | 28/55 [00:08<00:08,  3.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 53%|█████▎    | 29/55 [00:09<00:08,  3.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 55%|█████▍    | 30/55 [00:09<00:08,  3.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 56%|█████▋    | 31/55 [00:09<00:07,  3.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 58%|█████▊    | 32/55 [00:10<00:07,  3.04it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 60%|██████    | 33/55 [00:10<00:07,  3.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 62%|██████▏   | 34/55 [00:10<00:06,  3.07it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 64%|██████▎   | 35/55 [00:11<00:06,  3.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 65%|██████▌   | 36/55 [00:11<00:06,  3.06it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 67%|██████▋   | 37/55 [00:11<00:05,  3.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 69%|██████▉   | 38/55 [00:11<00:05,  3.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 71%|███████   | 39/55 [00:12<00:05,  3.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 73%|███████▎  | 40/55 [00:12<00:04,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 75%|███████▍  | 41/55 [00:12<00:04,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 76%|███████▋  | 42/55 [00:13<00:04,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 78%|███████▊  | 43/55 [00:13<00:03,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 80%|████████  | 44/55 [00:13<00:03,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 82%|████████▏ | 45/55 [00:14<00:03,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 84%|████████▎ | 46/55 [00:14<00:02,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 85%|████████▌ | 47/55 [00:14<00:02,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 87%|████████▋ | 48/55 [00:15<00:02,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 89%|████████▉ | 49/55 [00:15<00:01,  3.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 91%|█████████ | 50/55 [00:15<00:01,  3.08it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 93%|█████████▎| 51/55 [00:16<00:01,  3.09it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 95%|█████████▍| 52/55 [00:16<00:00,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 96%|█████████▋| 53/55 [00:16<00:00,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015 98%|█████████▊| 54/55 [00:17<00:00,  3.10it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 55/55 [00:17<00:00,  3.40it/s]#033[A#015                                                   #015\u001b[0m\n",
      "\u001b[34m#015                                               #015#033[A#015100%|██████████| 1314/1314 [11:25<00:00,  2.50it/s]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 55/55 [00:17<00:00,  3.40it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                               #033[A\u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34m#015                                                   #015#015100%|██████████| 1314/1314 [11:25<00:00,  2.50it/s]#015100%|██████████| 1314/1314 [11:25<00:00,  1.92it/s]\u001b[0m\n",
      "\u001b[34mThe following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text.\u001b[0m\n",
      "\u001b[34m***** Running Evaluation *****\n",
      "  Num examples = 3500\n",
      "  Batch size = 64\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/55 [00:00<?, ?it/s]#015  4%|▎         | 2/55 [00:00<00:08,  6.24it/s]#015  5%|▌         | 3/55 [00:00<00:11,  4.40it/s]#015  7%|▋         | 4/55 [00:00<00:13,  3.80it/s]#015  9%|▉         | 5/55 [00:01<00:14,  3.53it/s]#015 11%|█         | 6/55 [00:01<00:14,  3.35it/s]#015 13%|█▎        | 7/55 [00:01<00:14,  3.26it/s]#015 15%|█▍        | 8/55 [00:02<00:14,  3.21it/s]#015 16%|█▋        | 9/55 [00:02<00:14,  3.18it/s]#015 18%|█▊        | 10/55 [00:02<00:14,  3.14it/s]#015 20%|██        | 11/55 [00:03<00:14,  3.10it/s]#015 22%|██▏       | 12/55 [00:03<00:13,  3.11it/s]#015 24%|██▎       | 13/55 [00:03<00:13,  3.08it/s]#015 25%|██▌       | 14/55 [00:04<00:13,  3.07it/s]#015 27%|██▋       | 15/55 [00:04<00:12,  3.08it/s]#015 29%|██▉       | 16/55 [00:04<00:12,  3.09it/s]#015 31%|███       | 17/55 [00:05<00:12,  3.09it/s]#015 33%|███▎      | 18/55 [00:05<00:11,  3.09it/s]#015 35%|███▍      | 19/55 [00:05<00:11,  3.10it/s]#015 36%|███▋      | 20/55 [00:06<00:11,  3.10it/s]#015 38%|███▊      | 21/55 [00:06<00:10,  3.10it/s]#015 40%|████      | 22/55 [00:06<00:10,  3.08it/s]#015 42%|████▏     | 23/55 [00:07<00:10,  3.07it/s]#015 44%|████▎     | 24/55 [00:07<00:10,  3.08it/s]#015 45%|████▌     | 25/55 [00:07<00:09,  3.09it/s]#015 47%|████▋     | 26/55 [00:08<00:09,  3.10it/s]#015 49%|████▉     | 27/55 [00:08<00:09,  3.10it/s]#015 51%|█████     | 28/55 [00:08<00:08,  3.11it/s]#015 53%|█████▎    | 29/55 [00:09<00:08,  3.11it/s]#015 55%|█████▍    | 30/55 [00:09<00:08,  3.11it/s]#015 56%|█████▋    | 31/55 [00:09<00:07,  3.11it/s]#015 58%|█████▊    | 32/55 [00:10<00:07,  3.11it/s]#015 60%|██████    | 33/55 [00:10<00:07,  3.11it/s]#015 62%|██████▏   | 34/55 [00:10<00:06,  3.11it/s]#015 64%|██████▎   | 35/55 [00:10<00:06,  3.11it/s]#015 65%|██████▌   | 36/55 [00:11<00:06,  3.11it/s]#015 67%|██████▋   | 37/55 [00:11<00:05,  3.11it/s]#015 69%|██████▉   | 38/55 [00:11<00:05,  3.11it/s]#015 71%|███████   | 39/55 [00:12<00:05,  3.12it/s]#015 73%|███████▎  | 40/55 [00:12<00:04,  3.12it/s]#015 75%|███████▍  | 41/55 [00:12<00:04,  3.12it/s]#015 76%|███████▋  | 42/55 [00:13<00:04,  3.11it/s]#015 78%|███████▊  | 43/55 [00:13<00:03,  3.11it/s]#015 80%|████████  | 44/55 [00:13<00:03,  3.11it/s]#015 82%|████████▏ | 45/55 [00:14<00:03,  3.11it/s]#015 84%|████████▎ | 46/55 [00:14<00:02,  3.11it/s]#015 85%|████████▌ | 47/55 [00:14<00:02,  3.10it/s]#015 87%|████████▋ | 48/55 [00:15<00:02,  3.10it/s]#015 89%|████████▉ | 49/55 [00:15<00:01,  3.11it/s]#015 91%|█████████ | 50/55 [00:15<00:01,  3.11it/s]#015 93%|█████████▎| 51/55 [00:16<00:01,  3.11it/s]#015 95%|█████████▍| 52/55 [00:16<00:00,  3.11it/s]#015 96%|█████████▋| 53/55 [00:16<00:00,  3.11it/s]#015 98%|█████████▊| 54/55 [00:17<00:00,  3.10it/s]#015100%|██████████| 55/55 [00:17<00:00,  3.40it/s]#015100%|██████████| 55/55 [00:17<00:00,  3.17it/s]\u001b[0m\n",
      "\u001b[34mSaving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\n",
      "2022-10-05 23:40:47 Completed - Training job completed\n",
      "Training seconds: 1286\n",
      "Billable seconds: 1286\n"
     ]
    }
   ],
   "source": [
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit({\"train\": training_input_path, \"test\": test_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serverless Configuration\n",
    "\n",
    "#### Memory size - `memory_size_in_mb`\n",
    "Your serverless endpoint has a minimum RAM size of <b>1024 MB (1 GB)</b>, and the maximum RAM size you can choose is 6144 MB (6 GB). The memory sizes you can select are <b>1024 MB</b>, <b>2048 MB</b>, <b>3072 MB</b>, <b>4096 MB</b>, <b>5120 MB</b>, or <b>6144 MB. Serverless Inference auto-assigns compute resources proportional to the memory you select. If you select a larger memory size, your container has access to more `vCPUs`. Select your endpoint’s memory size according to your model size. Generally, the memory size should be at least as large as your model size. You may need to benchmark in order to select the right memory selection for your model based on your latency SLAs. The memory size increments have different pricing; see the Amazon SageMaker pricing page for more information.\n",
    "\n",
    "#### Concurrent invocations - `max_concurrency`\n",
    "   \n",
    "Serverless Inference manages predefined scaling policies and quotas for the capacity of your endpoint. Serverless endpoints have a quota for how many concurrent invocations can be processed at the same time. If the endpoint is invoked before it finishes processing the first request, then it handles the second request concurrently. You can set the maximum concurrency for a <b>single endpoint up to 50</b>, and the total number of serverless endpoint variants you can host in a Region is 50. The total concurrency you can share between all serverless endpoints per Region in your account is 200. The maximum concurrency for an individual endpoint prevents that endpoint from taking up all the invocations allowed for your account, and any endpoint invocations beyond the maximum are throttled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serverless.serverless_inference_config import ServerlessInferenceConfig\n",
    "\n",
    "serverless_config = ServerlessInferenceConfig(\n",
    "    memory_size_in_mb=6144,\n",
    "    max_concurrency=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace Inference Image `URI`\n",
    "\n",
    "In order to deploy the SageMaker Endpoint with Serverless configuration, we will need to supply the HuggingFace Inference Image URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-inference:1.9-transformers4.10-cpu-py38-ubuntu20.04'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"huggingface\",\n",
    "    base_framework_version=\"pytorch1.9\",\n",
    "    region=sess.boto_region_name,\n",
    "    version=\"4.10\",\n",
    "    py_version=\"py38\",\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    image_scope=\"inference\",\n",
    ")\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serverless Endpoint Creation\n",
    "Now that we have a `ServerlessInferenceConfig`, we can create a serverless endpoint and deploy our model to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictor = huggingface_estimator.deploy(\n",
    "    serverless_inference_config=serverless_config, image_uri=image_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint Invocation\n",
    "\n",
    "Using few samples, you can now invoke the SageMaker endpoint to get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(sentence):\n",
    "    result = predictor.predict({\"inputs\": sentence})\n",
    "    index = int(result[0][\"label\"].split(\"LABEL_\")[1])\n",
    "    print(categories[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"The modem is an internal AT/(E)ISA 8-bit card (just a little longer than a half-card).\",\n",
    "    \"In the cage I usually wave to bikers.  They usually don't wave back.  My wife thinks it's strange but I don't care.\",\n",
    "    \"Voyager has the unusual luck to be on a stable trajectory out of the solar system.\",\n",
    "]\n",
    "\n",
    "# using the same processing logic that we used during data preparation for training\n",
    "processed_sentences = process_text(sentences)\n",
    "\n",
    "for sentence in processed_sentences:\n",
    "    predict_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Invoke a deployed endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Endpoints\": [\n",
      "        {\n",
      "            \"EndpointName\": \"huggingface-pytorch-training-2022-10-05-23-57-02-171\",\n",
      "            \"EndpointArn\": \"arn:aws:sagemaker:us-west-2:976939723775:endpoint/huggingface-pytorch-training-2022-10-05-23-57-02-171\",\n",
      "            \"CreationTime\": \"2022-10-05T23:57:03.057000+00:00\",\n",
      "            \"LastModifiedTime\": \"2022-10-06T00:02:52.623000+00:00\",\n",
      "            \"EndpointStatus\": \"InService\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker list-endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "generator = pipeline('text-generation', model = 'gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "Payloads = generator(\"Elon Musk's Twitter acquisition\", max_length = 80, num_return_sequences=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Elon Musk's Twitter acquisition looks to be another example with Tesla. Musk has said that Musk will help the company establish its own distribution center network in California, which will help ensure that all cars sold within that region are sold at the same prices on the rest of the U.S.' roads.\\n\\nWhile the details of the move were left to Tesla employees, Bloomberg notes that Musk's team\"},\n",
       " {'generated_text': 'Elon Musk\\'s Twitter acquisition of Tesla seems a bit more like a marketing ploy than something to be taken seriously by the media.\\n\\nNow, I don\\'t think it\\'s because Musk is a \"great guy,\" as everyone is being falsely accused of, or because he\\'s a narcissist; he really has the personality — and his energy and enthusiasm and determination to become the greatest engineer in history'},\n",
       " {'generated_text': \"Elon Musk's Twitter acquisition is one of the biggest, most interesting and interesting business deals in the internet age. This also has several interesting things happening. First of all, there are a lot of people with money. It's a business model that has huge potential in the long run... and also in the short term, many of the other big players in the internet space have a long-term\"},\n",
       " {'generated_text': \"Elon Musk's Twitter acquisition makes a lot of sense. Tesla may want to keep buying its current manufacturing facility and investing in its other manufacturing lines, even if it makes fewer profits (or possibly doesn't). Its business model in the United States isn't very business-like and it doesn't have good management to back it up with good results.\\n\\nWhen I asked Musk if Tesla did not\"},\n",
       " {'generated_text': 'Elon Musk\\'s Twitter acquisition continues to expand on several other fronts, including the role of social media to address more issues than ever.\\n\\nFor example, Musk recently announced Musk\\'s plan to build his first business that would become the world\\'s foremost in aerospace. The initial version of the Falcon-25, called the \"Space X Flight Simulation Hub,\" was built by Boeing Space Systems to simulate'},\n",
       " {'generated_text': \"Elon Musk's Twitter acquisition of Titan Air—which is also an investment in SpaceX—was announced on March 28.\\n\\nSpaceX's announcement comes one day after a group of scientists announced Tuesday that it is scaling up its long-term research program to develop vehicles for the next generation of spaceplanes. While the company does not yet reveal the technology it is developing for the next generation of astronauts\"},\n",
       " {'generated_text': \"Elon Musk's Twitter acquisition of Facebook ended in a blow to rival company Facebook.\\n\\nTesla, which is owned by Tesla Motors, closed for $5 billion Thursday. Tesla shares jumped more than 2 percent to $33.31 in premarket trading.\\n\\nThe deal followed the company's announcement Friday that Musk, 61, was the original owner of Musk Motors, a lithium-ion battery\"},\n",
       " {'generated_text': \"Elon Musk's Twitter acquisition last week was an attempt to shore up the Space Race between Elon Musk and Boeing by selling the company to Boeing. That plan was thwarted by a court ruling, and in the wake of that, President Barack Obama has vowed to end the Air Force's involvement in NASA.\\n\\nIn May 2013, NASA's Office of Science Devolutions issued an internal request for advice on\"},\n",
       " {'generated_text': \"Elon Musk's Twitter acquisition of a second startup to develop a business program has been widely believed to have been done to bolster the company's efforts to expand beyond gaming, particularly as the company's share price has fallen steadily over the last two days. While the price of an Xbox One and three more are expected to hit $500 with sales likely increasing in the coming months, that may not prove to\"},\n",
       " {'generated_text': \"Elon Musk's Twitter acquisition is a bold move, and many investors felt the investor was in the wrong place at the wrong time.\"},\n",
       " {'generated_text': 'Elon Musk\\'s Twitter acquisition of T-Mobile has ignited a debate among the tech industry over the viability of T-Mobile\\'s plans. In a report released Friday, the Mobile Industry Association found that more than 1,000 new customers would cancel their plans.\\n\\nMusk, a former CEO of T-Mobile and executive vice president of communications in Travail, called this \"market failure'},\n",
       " {'generated_text': 'Elon Musk\\'s Twitter acquisition\\n\\nMusk told VentureBeat that Tesla\\'s new headquarters in Hawthorne, California, is a unique opportunity.\\n\\nHe claimed that Musk is \"going to build another skyscraper in one city\" after he bought Tesla in 2013.\\n\\nWith Tesla\\'s financial performance at its lowest level since 2005, Musk is expected to spend between $35 million and $50'},\n",
       " {'generated_text': \"Elon Musk's Twitter acquisition is going on its way at the moment, and if you look closely at the list, there's a clear, clear pattern with how it works. It will be a few months before it becomes mainstream, and there's actually no reason for the company not to work on Tesla on the car project as it exists right now, since Tesla would probably want to create its own\"},\n",
       " {'generated_text': \"Elon Musk's Twitter acquisition includes two other companies, and the U.S. Department of Energy (DOE), which has been in partnership with EROI for almost a year, is expected to begin reviewing the sale of SolarCity's assets. This is not the first meeting of its kind between the two companies.\\n\\nThe Wall Street Journal reports that ExxonMobil had reached an agreement to\"},\n",
       " {'generated_text': \"Elon Musk's Twitter acquisition of LinkedIn was well underway. There are reports that Musk was given the CEO role by Microsoft in his quest to lead the $20 billion tech start-up.\\n\\nMicrosoft wants Musk to helm that tech business but could take a job as cofounder of Google. More to come.\\n\\nA former CEO of Tesla Motors was also mentioned.\\n\\nRelated:\\n\"},\n",
       " {'generated_text': \"Elon Musk's Twitter acquisition of New York's TIFF\\n\\nThe San Francisco-based operator of Twitter will acquire New York-based TIFF, after a two-year search conducted by The Wall Street Journal at last February's New York Stock Exchange and other publications. The transaction was approved by Fidelity Holdings LP, valued at P/E $6.15 billion at 6.38 percent\"},\n",
       " {'generated_text': \"Elon Musk's Twitter acquisition of Instagram has made headlines. In March, the world's largest social network announced that the company had signed a deal to build a social network for entrepreneurs and other large financial institutions. Today, the Twitter giant has a billion users and, with $13.6 billion in revenue, operates more than 250 million sites. The new app, dubbed Facebook Messenger, will replace Messenger\"},\n",
       " {'generated_text': \"Elon Musk's Twitter acquisition of SpaceX, and Elon is taking a closer look at the technology he'll be working with in the coming months, just days before the launch of the Falcon 9 rocket, reports Wired.\\n\\nMusk's plan for SpaceX to be the first commercial flight to include a cargo ship is currently under-developed, but he has expressed interest in looking at whether to develop\"},\n",
       " {'generated_text': \"Elon Musk's Twitter acquisition is not surprising given that the company operates more than 20,000 solar installations per year in the United States and 20,000 other green technologies. Musk has previously stated that solar is likely to create as much as two-thirds of global green energy by 2020, based on the use of solar electricity.\\n\\nThe deal is expected to net Tesla $40 billion over 10\"},\n",
       " {'generated_text': 'Elon Musk\\'s Twitter acquisition is only the latest high-profile example of the company having a significant influence on the way people think about the company.\"\\n\\nAs Bloomberg notes:\\n\\nWith the help of an undisclosed government source, it emerged last week that Tesla Co is reportedly planning a $2 billion investment. A government source has told Bloomberg in two separate phone calls this week that the deal will'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Payloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"label\":\"LABEL_3\",\"score\":0.5238500833511353}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9861999750137329}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9365861415863037}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.7964444756507874}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9765886068344116}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9878882765769958}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9759885668754578}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.971071720123291}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.6195178627967834}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9910324215888977}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9304075241088867}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.7927928566932678}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9872843027114868}]\n",
      "[{\"label\":\"LABEL_0\",\"score\":0.7753292918205261}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9681625962257385}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9863579273223877}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.527592122554779}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.5489237308502197}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9933062195777893}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.985008955001831}]\n",
      "[{\"label\":\"LABEL_0\",\"score\":0.6789974570274353}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9937187433242798}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.45356109738349915}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.736049234867096}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.7312458157539368}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.5298811793327332}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9903153777122498}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.7150442600250244}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.3872857987880707}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9656223058700562}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9487020969390869}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9907267093658447}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.3197236657142639}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9903152585029602}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.7517138123512268}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.891867995262146}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.6797960996627808}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9192507266998291}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.5507851839065552}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.8143513202667236}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9909664392471313}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9888324737548828}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.5397582054138184}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9692143201828003}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.39753350615501404}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.43783172965049744}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.993498682975769}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.4174758195877075}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.680585503578186}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.4344843626022339}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9822865128517151}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.983954906463623}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.6243789792060852}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9910051822662354}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9928770661354065}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.42672184109687805}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9937631487846375}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9882227778434753}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9767521023750305}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.337463915348053}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.7511951923370361}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.986261785030365}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9938179850578308}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9899237751960754}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.8342671394348145}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9054344296455383}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9924343824386597}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.8747812509536743}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9636462330818176}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9825319051742554}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.43613260984420776}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9398795366287231}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.553447961807251}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.7124105095863342}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9629660248756409}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.43081265687942505}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.995230495929718}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.7096960544586182}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9938933253288269}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.5548875331878662}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9075326323509216}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9907717704772949}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.5156795382499695}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.8792173862457275}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9336279630661011}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.953971803188324}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.5311759114265442}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9940934777259827}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9676952958106995}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.6005544066429138}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9587451815605164}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.4609556198120117}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9143566489219666}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.933589518070221}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.6725308895111084}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.38143739104270935}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9267228245735168}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9529514908790588}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.4617772698402405}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9550815224647522}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.4935722053050995}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9945871829986572}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9892838597297668}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9021178483963013}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.992967963218689}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.7104590535163879}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.5307102799415588}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.6319840550422668}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9935898780822754}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.8896123766899109}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9492112398147583}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.6764875054359436}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9848363995552063}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.8458338379859924}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.979333221912384}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9940568208694458}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9920859932899475}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.44546541571617126}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9775539040565491}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9943898320198059}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.37230244278907776}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.44773977994918823}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.6121572852134705}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.8627054691314697}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9877896308898926}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.970064640045166}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.7479845881462097}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9941376447677612}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.5246725678443909}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9818026423454285}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.4275091588497162}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.3513454794883728}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.4728950560092926}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.7516534924507141}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9500656127929688}]\n",
      "[{\"label\":\"LABEL_0\",\"score\":0.484409362077713}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9857239127159119}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.8859170079231262}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.8319252133369446}]\n",
      "[{\"label\":\"LABEL_0\",\"score\":0.9502894878387451}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.4891379475593567}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.8888140320777893}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.854394793510437}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.7916585803031921}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.8203396797180176}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9678804278373718}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.986810564994812}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9084093570709229}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9833884239196777}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.5412163138389587}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.7434520125389099}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9769083261489868}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.7615734338760376}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9562657475471497}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.76507169008255}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.4061594307422638}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.8124154806137085}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9890275001525879}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.927888035774231}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.5377411246299744}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.8894598484039307}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.967073380947113}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.874347984790802}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9933370351791382}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9727091789245605}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9904260039329529}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.5980985760688782}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.4380442500114441}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9817627668380737}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9932551383972168}]\n",
      "[{\"label\":\"LABEL_0\",\"score\":0.9694705009460449}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.582816481590271}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9811193943023682}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9486295580863953}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9781347513198853}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9876939058303833}]\n",
      "[{\"label\":\"LABEL_0\",\"score\":0.908807635307312}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.34428900480270386}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.8552864193916321}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.6502810716629028}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.8449245095252991}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9179843664169312}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9897515773773193}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.992587149143219}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9567538499832153}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9940272569656372}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9929524064064026}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.4207717478275299}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9911012649536133}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.707951009273529}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.9506696462631226}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.7875410914421082}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.9015666246414185}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.712509036064148}]\n",
      "[{\"label\":\"LABEL_1\",\"score\":0.5779173374176025}]\n",
      "[{\"label\":\"LABEL_4\",\"score\":0.5985520482063293}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.4479386508464813}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.9931012392044067}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.6783661246299744}]\n",
      "[{\"label\":\"LABEL_3\",\"score\":0.992849588394165}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "client = boto3.client('runtime.sagemaker')\n",
    "payload = {\"inputs\": \"The modem is an internal AT/(E)ISA 8-bit card (just a little longer than a half-card).\"}\n",
    "for i in range(len(Payloads)):\n",
    "    Payloads[i]['inputs'] = Payloads[i]['generated_text']\n",
    "    del Payloads[i]['generated_text']\n",
    "    response = client.invoke_endpoint(EndpointName='huggingface-pytorch-training-2022-10-05-23-57-02-171', \n",
    "                                      ContentType=\"application/json\",\n",
    "                                      Body=json.dumps(Payloads[i]),\n",
    "                                     )\n",
    "    print(response[\"Body\"].read().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Endpoints should be deleted when no longer in use, since (per the [SageMaker pricing page](https://aws.amazon.com/sagemaker/pricing/)) they're billed by time deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook you successfully ran SageMaker Training Job with the HuggingFace framework to fine-tune a pre-trained transformer on text classification using the `20 newsgroups dataset` dataset.\n",
    "Then, you prepared the Serverless configuration required, and deployed your model to SageMaker Serverless Endpoint. Finally, you invoked the Serverless endpoint with sample data and got the prediction results.\n",
    "\n",
    "As next steps, you can try running SageMaker Training Jobs with your own algorithm and your own data, and deploy the model to SageMaker Serverless Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "c281c456f1b8161c8906f4af2c08ed2c40c50136979eaae69688b01f70e9f4a9"
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
